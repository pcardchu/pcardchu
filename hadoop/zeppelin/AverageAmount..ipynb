{
  "metadata": {
    "name": "AverageAmount",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\n\nspark \u003d SparkSession.builder.master(\"yarn\").appName(\"card 201909 test1\").config(\"spark.cassandra.connection.host\", \"172.21.0.6\").getOrCreate()\n\nfile_path \u003d \"hdfs:///example/card_201909.csv\"\nfile_path2 \u003d \"hdfs:///example/card_201910.csv\"\nfile_path3 \u003d \"hdfs:///example/card_201911.csv\"\nfile_path4 \u003d \"hdfs:///example/card_201912.csv\"\n\ndf1 \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"false\").option(\"encoding\", \"EUC-KR\").load(file_path)\ndf2 \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"false\").option(\"encoding\", \"EUC-KR\").load(file_path2)\ndf3 \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"false\").option(\"encoding\", \"EUC-KR\").load(file_path3)\ndf4 \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"false\").option(\"encoding\", \"EUC-KR\").load(file_path4)\n\ndf \u003d df1.union(df2).union(df3).union(df4)\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nfrom pyspark.sql.types import IntegerType\n\ndfselect \u003d df.select(\n        F.substring(df.성별, 3,2).alias(\"gender\"),\n        F.substring(df.연령, 3, 3).alias(\"age\"),\n        df.개인기업구분.alias(\"split\"),\n        df.결제금액.cast(IntegerType()).alias(\"amount\")\n    )\n\n\ndfselect.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nfrom pyspark.sql.functions import dense_rank, col, count\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import IntegerType\n\n# 성별, 연령대로 그룹화하고, 평균 결제금액 계산\nageGroupAverage \u003d dfselect.filter((col(\"gender\") !\u003d \"기업\") \u0026 (col(\"age\") !\u003d \"기타\")).groupBy(\"gender\", \"age\").agg(F.avg(\"amount\").cast(IntegerType()).alias(\"average\"))\n\n\nageGroupAverage.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nfrom pyspark.sql.functions import monotonically_increasing_id\naverage_amount_df \u003d ageGroupAverage.select(monotonically_increasing_id().alias(\u0027id\u0027),ageGroupAverage.age, ageGroupAverage.gender, ageGroupAverage.average)\naverage_amount_df.write.format(\u0027org.apache.spark.sql.cassandra\u0027).mode(\u0027append\u0027).option(\"keyspace\", \"trend\").option(\"table\", \"averageamount\").option(\"spark.cassandra.output.consistency.level\", \"ONE\").save()\n\n# 테스트\ndf_test \u003d spark.read.format(\"org.apache.spark.sql.cassandra\").options(table\u003d\"averageamount\", keyspace\u003d\"trend\").load()\ndf_test.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n"
    }
  ]
}