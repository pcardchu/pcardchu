# ë¶„ì‚° í™˜ê²½ ì„¤ì • ì´ ì •ë¦¬

---

EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì—¬ëŸ¬ ê°œ ë‘ë©´ í¸í•˜ì§€ë§Œ

ì œí•œëœ ìì›(EC2 í•œ ê°œ)ìœ¼ë¡œ ìš´ì˜í•´ì•¼í•˜ë¯€ë¡œ ë„ì»¤ ì»¨í…Œì´ë„ˆë¡œ ë…¸ë“œë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•´

ì´ëŸ¬í•œ ì‹œë„ë¥¼ í•˜ê²Œ ë˜ì—ˆìŒ.

<aside>
ğŸ’¡ ì‹œì‘í•˜ê¸° ì „ì—, ì•„ì‰¬ì› ë˜ ì  ëª‡ ê°€ì§€ë¥¼ ë¨¼ì € ì–¸ê¸‰í•˜ìë©´

1) dockerì—ì„œ rootê¶Œí•œìœ¼ë¡œ ëª¨ë“  ê²ƒì„ ì‹¤í–‰í•œ  ê²ƒì„.

ë§Œì•½ ë˜ êµ¬ì¶•í•  ì¼ì´ ìƒê¸´ë‹¤ë©´ ì»¨í…Œì´ë„ˆë§ˆë‹¤ ì‚¬ìš©ìë¥¼ í•˜ë‚˜ ë§Œë“¤ì–´ì„œ ê·¸ ê³³ì—ì„œ ìˆ˜í–‰í•  ê²ƒ ê°™ë‹¤.
2) ì»¨í…Œì´ë„ˆë¥¼ ì¼ì¼ì´ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ë²ˆê±°ë¡­ê³ , ë‚˜ì¤‘ì— Airflowë„ í•¨ê»˜ ì“°ë ¤ë©´ ë¯¸ë¦¬ docker composeë¥¼ ì„¤ì¹˜í•´ì„œ ì‚¬ìš©í•˜ë©´ ì¢‹ì•˜ì„ ë“¯ í•˜ë‹¤.
3) ì¶”ê°€ë¡œ ê´€ë¦¬ ë„êµ¬ë¡œ Kubernetes ì‚¬ìš©ë„ í•œë²ˆ ê³ ë ¤í•´ë³´ê³  ì‹¶ë‹¤.

4) 24.04.02 ë¦¬ì†ŒìŠ¤ ê³¼ë‹¤ë¡œ ì„œë²„ê°€ ì£½ì—ˆë‹¤.
   ë„ì»¤ ë³¼ë¥¨ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‘ê²Œ ì„¤ì •í•œ ê²ƒë„ ë¬¸ì œì´ê³ , zeppelin ë©”ëª¨ë¦¬ë„ ì‘ê²Œ ì„¤ì •í•œ ê²ƒì´ ë¬¸ì œì¸ ë“¯í•˜ë‹¤. 
ê·¸ë¦¬ê³  ê¸°ë³¸ì ìœ¼ë¡œ Cassandra, Zeppelinì´ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì¡ì•„ë¨¹ëŠ”ë°, í…ŒìŠ¤íŠ¸ í•˜ëŠë¼ Cassandra IO ì‘ì—…ì´ ë„ˆë¬´ ë§ì•˜ë˜ ê²ƒë„ ë¬¸ì œì˜€ë‹¤.

ê·¸ë¦¬ê³  Airflowê°€ (íŠ¹íˆ trigger) CPU ì‚¬ìš©ëŸ‰ì„ 100%ì´ìƒ ì°¨ì§€í–ˆë‹¤.

</aside>

> **base node ì„¤ì¹˜ & í•„ìˆ˜ ì„¤ì¹˜ í”„ë¡œê·¸ë¨**
> 

1) ë„ì»¤ ë„¤íŠ¸ì›Œí¬ ìƒì„±

```bash
# zeppelin ë‚´ë¶€ í†µì‹ ì„ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ë„¤íŠ¸ì›Œí¬ ìƒì„±
sudo docker network create d110-network

# base imageë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ë„ì»¤ íŒŒì¼ ìƒì„±
nano Dockerfile
```

2) Dockerfile ì‘ì„±

```bash
FROM ubuntu:20.04

# install essential libraries
RUN apt-get -y update
RUN apt-get -y upgrade
RUN apt-get -y dist-upgrade

RUN apt-get install -y wget unzip ssh openssh-* net-tools

# install java 1.8 for Hadoop
RUN apt-get install -y openjdk-8-jdk
RUN find / -name java-8-openjdk-amd64 2>/dev/null

# set environment variable
ENV PATH="${PATH}:/usr/lib/jvm/java-8-openjdk-amd64/bin"
ENV JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"

SHELL ["/bin/bash", "-c"]
RUN echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc
RUN source ~/.bashrc

# install python 3.8
RUN apt-get install -y python3-pip

# ssh setup
RUN ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
RUN cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
RUN chmod 0600 ~/.ssh/authorized_keys

# install hadoop
RUN wget https://dlcdn.apache.org/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz
RUN tar -zxvf hadoop-3.2.4.tar.gz
RUN mv hadoop-3.2.4 hadoop

# set environment variable
ENV PATH="${PATH}:/root/cluster/hadoop/bin:/root/cluster/hadoop/sbin"
ENV HADOOP_HOME="/root/cluster/hadoop"

RUN echo 'export HADOOP_HOME=/root/cluster/hadoop' >> ~/.bashrc;
RUN echo 'export HADOOP_COMMON_HOME=$HADOOP_HOME' >> ~/.bashrc;
RUN echo 'export HADOOP_HDFS_HOME=$HADOOP_HOME' >> ~/.bashrc;
RUN echo 'export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop' >> ~/.bashrc;
RUN echo 'export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop' >> ~/.bashrc;
RUN echo 'export HADOOP_YARN_HOME=$HADOOP_HOME' >> ~/.bashrc;
RUN echo 'export HADOOP_MAPRED_HOME=$HADOOP_HOME' >> ~/.bashrc;

RUN source ~/.bashrc
```

 - ì›ë˜ í•˜ë‘¡ì‹œìŠ¤í…œì—ì„œë„ ë³´ì•ˆì„ ìœ„í•´ ì‚¬ìš©ìë¥¼ í•˜ë‚˜ ë§Œë“œëŠ” ê²ƒì´ ë§ìŒ

 - ê·¸ëŸ°ë° ë„ì»¤ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•  ì‹œ root ê¶Œí•œìœ¼ë¡œ ë¨¼ì € ë“¤ì–´ê°€ì§.
 - ë”°ë¼ì„œ í¸ì˜ìƒ root ê¶Œí•œìœ¼ë¡œ ìš´ì˜, ì´ë•Œ í™ˆ ë””ë ‰í† ë¦¬ê°€ /home/ubuntuê°€ ì•„ë‹Œ /root ì„ì„ ì£¼ì˜ + sudo í‚¤ì›Œë“œ ì—†ìŒ ì£¼ì˜

 - hadoop ë“±ë“± ì—¬ëŸ¬ íŒŒì¼ë“¤ì˜ ê²½ìš° ë²„ì „ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë‹¤ìš´ë°›ì„ ê²ƒ.

3) ë„ì»¤ íŒŒì¼ ëŒ€ë¡œ ì´ë¯¸ì§€ ë¹Œë“œ

```bash
# í˜„ì¬ í´ë”ì—ì„œ 'Dockerfile'ì„ ì°¾ì•„ ì´ íŒŒì¼ëŒ€ë¡œ init-imageë¼ëŠ” ì´ë¯¸ì§€ë¥¼ ë¹Œë“œ
sudo docker build -t init-image .

# ì´ë¯¸ì§€ í™•ì¸
sudo docker images
```

4) ë„ì»¤ ì»¨í…Œì´ë„ˆ ìƒì„± - ë§ˆìŠ¤í„° ë„¤ì„ë…¸ë“œ

**ì£¼ì˜!! ë°˜ë“œì‹œ ì»¨í…Œì´ë„ˆë¥¼ ì²˜ìŒ ìƒì„±í•  ë•Œ í¬íŠ¸ë¥¼ ëª¨ë‘ ë¯¸ë¦¬ ì§€ì •í•´ì£¼ì–´ì•¼í•œë‹¤.**

```bash
sudo docker run -i -d --network d110-network --hostname master-namenode --name master-namenode -p 18080:18080 -p 8088:8088 -p 18888:18888 -p 50070:50070 -p 2181:2181 init-image
```

- -i ì˜µì…˜ì„ ê¼­ ë¶™ì—¬ì¤˜ì•¼ ì»¨í…Œì´ë„ˆ ìƒì„± ì‹œ ë°”ë¡œ Exitedë˜ì§€ ì•Šê³  ì‹¤í–‰ë¨.
- -d : ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰. ì•ˆë¶™ì´ë©´ ë°”ë¡œ ì ‘ì†ë˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œê³ ìˆìŒ
- --hostname : í˜¸ìŠ¤íŠ¸ë„¤ì„ë„ ë¶™ì´ë©´ í¸í•œë° ìƒì„±í•  ë•Œ ì•„ë‹ˆë©´ ìˆ˜ì •í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ë°˜ë“œì‹œ ì´ ë•Œ ì§€ì •í•´ì£¼ê¸°
- --network : ìœ„ì—ì„œ ì§€ì •í•´ì¤€ ë„¤íŠ¸ì›Œí¬ë¡œ ì—°ê²°í•˜ê¸°

ì—¬ê¸°ì„œ í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€ë¡œ ë§ˆì € ì„¤ì •í•´ ì¤€ ë‹¤ìŒ, ì´ê±¸ ì´ë¯¸ì§€í™” í•´ì„œ ë‚˜ë¨¸ì§€ ë…¸ë“œ ìƒì„± ì˜ˆì •

5) ì ‘ì† í›„ ì´ë¯¸ì§€ ê¸°ë°˜ ë‹¤ë¥¸ ë…¸ë“œë“¤ ìƒì„±

```bash
# ì ‘ì†
sudo docker exec -it <container-id> /bin/bash
```

- í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€ ì„¤ì •

```bash
# í™˜ê²½ë³€ìˆ˜ ë“±ë¡
nano /etc/environment
> PATH += :/usr/lib/jvm/java-8-openjdk-amd64/bin
> JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"

# Framework í™˜ê²½ë³€ìˆ˜ ì‚¬ì „ ì„¤ì •
> PATH += ":/root/cluster/hadoop/bin" 
> PATH += ":/root/cluster/hadoop/sbin"

> HADOOP_HOME="/root/cluster/hadoop"
> SPARK_HOME="/root/cluster/spark"
> ZOOKEEPER_HOME="/root/cluster/zookeeper"

source /etc/environment
```

 - ì—¬ê¸°ì„œë„ /home/ubuntu ëŒ€ì‹  /rootë¥¼ ì‚¬ìš©í–ˆìŒ ì£¼ì˜

- ì‘ì—…ìš© í´ë” ìƒì„±

```bash
mkdir ~/cluster

# ì´í›„ ìœ„ì—ì„œ ì„¤ì¹˜í–ˆë˜ í•˜ë‘¡ í´ë” ì˜®ê¸°ê¸°
```

- ë„ì»¤ ì´ë¯¸ì§€í™”

```bash
exit

sudo docker commit -m "make base node" <ì»¨í…Œì´ë„ˆ ì´ë¦„> <ìƒˆ ì´ë¯¸ì§€ ì´ë¦„>
```

- ë‹¤ë¥¸ ë…¸ë“œë“¤(secondary namenode, datanode, datanode2) ì»¨í…Œì´ë„ˆ ìƒì„±

```bash
sudo docker run -i -d --network d110-network --hostname master-secondary-namenode --name master-secondary-namenode -p 2182:2181 basenode-image
sudo docker run -i -d --network d110-network --hostname worker-datanode --name worker-datanode -p 2183:2181 basenode-image
sudo docker run -i -d --network d110-network --hostname worker-datanode2 --name worker-datanode2 basenode-image
```

 - master-secondary-namenode : 2182:2181 í¬íŠ¸í¬ì›Œë”©

 - worker-datanode: 2183:2181 í¬íŠ¸í¬ì›Œë”©

(zookeeperëŠ” ìµœì†Œ 3ê°œì˜ journal nodeê°€ í•„ìš”í•´ì„œ ìœ„ì˜ ë§ˆìŠ¤í„°ë„¤ì„ë…¸ë“œ í¬í•¨ 3ê°œë§Œ í¬íŠ¸ ì˜¤í”ˆ.)

 

6) ssh ì ‘ì†ì„ ìœ„í•œ í™˜ê²½ ì„¤ì •

```bash
# master nodeë¡œ ì ‘ì†
sudo docker exec -it <container-id> /bin/bash
```

** ssh ì ‘ì† í…ŒìŠ¤íŠ¸

ssh: connect to host localhost port 22: Cannot assign requested address

```bash
service ssh start

ssh localhost
```

- /etc/hosts ìˆ˜ì •

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/899c11c1-fb51-4b5c-a67f-fa9ae5829348/Untitled.png)

ìœ„ì²˜ëŸ¼ private ipì£¼ì†Œ í™•ì¸

ì‚¬ìš©ì ì •ì˜ ë„¤íŠ¸ì›Œí¬ì˜ ê²½ìš° 172.18 ë¶€í„° ì‹œì‘í•¨. (ìœ„ ì‚¬ì§„ì€ ë²Œì¨ ë„¤ë²ˆì§¸ ë„¤íŠ¸ì›Œí¬â€¦)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/34a97a52-91b3-4c25-80ed-38bc9ef2cb06/Untitled.png)

- ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆì—ë„ ì ìš©

```bash
cat /etc/hosts | ssh master-secondary-namenode "sh -c 'cat >/etc/hosts'"
cat /etc/hosts | ssh worker-datanode "sh -c 'cat >/etc/hosts'"
cat /etc/hosts | ssh worker-datanode2 "sh -c 'cat >/etc/hosts'"
```

### **ğŸ’¢ Trouble Shooting - ssh**

<aside>
ğŸ’¡ **Host key verification failed**

</aside>

ì´ëŸ°ê±¸ ì—¬ëŸ¬ë²ˆì‹œë„í–ˆë”ë‹ˆ ìê¾¸ host key verification failed ë¬¸ì œ ë°œìƒ

ì²˜ìŒ í•œë‘ë²ˆì€ ì˜ë¨..

ëª©í‘œ: ssh ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ì—†ì´ â€˜ssh í˜¸ìŠ¤íŠ¸ë„¤ì„â€™ ë§Œìœ¼ë¡œë„ ììœ ë¡œì´ ì ‘ì†í•˜ê¸°

1) ssh-keygen -t rsa ë¡œ keyë¥¼ ìƒì„±

2) id_rsa, id_rsa.pub, authorized_keysë¥¼ ê°€ì§„ ì±„ë¡œ ì´ë¯¸ì§€ ìƒì„±

3) ì´ ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì»¨í…Œì´ë„ˆë“¤ ìƒì„±

4) ssh ì ‘ì†

â‡’ Host key verification failed ë¬¸ì œ ë°œìƒ

â‡’ ssh-keygen -R í˜¸ìŠ¤íŠ¸ë„¤ì„ ì„ í™œìš©í•˜ì—¬ ì´ˆê¸°í™”

â‡’ known_hostsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ë‹¤ëŠ” ë¬¸ì œ ë°œìƒ(í˜¸ìŠ¤íŠ¸ë„¤ì„ or ipê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ë¬¸ì œ ë°œìƒ)

â‡’ ì—¬ê¸°ì„œ ë§ì´ ê³ ë¯¼í–ˆëŠ”ë° ê·¸ëƒ¥,

**known_hostsì—ì„œ í•´ë‹¹ ì§€ë¬¸ì„ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ssh ì ‘ì†ì„ ì‹œë„í•˜ë©´ ëœë‹¤.**

7) í•„ìˆ˜ í”„ë¡œê·¸ë¨ ì„¤ì¹˜

```bash
# ZOOKEEPER 3.8.4
cd ~/cluster;
wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz;
tar -xzvf apache-zookeeper-3.8.4-bin.tar.gz;
mv apache-zookeeper-3.8.4-bin ~/cluster/zookeeper;

# SPARK 3.2.4
cd ~/cluster;
wget https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz;
tar -xvf spark-3.2.4-bin-hadoop3.2.tgz;
mv spark-3.2.4-bin-hadoop3.2 ~/cluster/spark;

# ZEPPELIN 0.10.1
cd ~/cluster;
wget https://dlcdn.apache.org/zeppelin/zeppelin-0.10.1/zeppelin-0.10.1-bin-all.tgz;
```

 - ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ì„œ ë²„ì „ì„ ì²´í¬í•˜ê³  ë‹¤ìš´ ë°›ì„ ê²ƒ. (ì•„ë‹ˆë©´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  404 ì˜¤ë¥˜ë‚¨)

> **í•˜ë‘¡ í™˜ê²½ ì„¤ì •**
> 

1) hdfs-site.xml ìˆ˜ì •

```xml
    <!-- Put site-specific property overrides in this file. -->
<configuration>
    <!-- hdfs basic configuration-->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/root/cluster/data/dfs/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/root/cluster/data/dfs/datanode</value>
    </property>

    <!-- configuration for HA and Federation -->
    <property>
        <name>dfs.nameservices</name>
        <value>dfs-cluster</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.dfs-cluster</name>
        <value>namenode1,namenode2</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.dfs-cluster.namenode1</name>
        <value>master-namenode:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.dfs-cluster.namenode2</name>
        <value>master-secondary-namenode:8020</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.dfs-cluster.namenode1</name>
        <value>master-namenode:50070</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.dfs-cluster.namenode2</name>
        <value>master-secondary-namenode:50070</value>
    </property>

    <!-- journalnodes group-->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://master-namenode:8485;master-secondary-namenode:8485;worker-datanode:8485/dfs>
    </property>
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/root/cluster/data/dfs/journalnode</value>
    </property>

    <!-- configuration of fail-over-->
    <property>
        <name>dfs.client.failover.proxy.provider.dfs-cluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
</configuration>

```

 - namenode service idë¡œ dfs-clusterë¼ê³  ì§€ì–´ì¤Œ. 

 - ê·¸ë¦¬ê³  ì„œë¹„ìŠ¤ì˜ ë„¤ì„ë…¸ë“œë“¤ì„ ì•ì„œ ë§Œë“¤ì–´ì¤€ 2ê°œì˜ ë„¤ì„ë…¸ë“œë¡œ ì§€ì •í•´ì¤Œ.

2) core-site.xml ìˆ˜ì •

```xml
<configuration>
    <!-- Set HDFS default file system, Heartbeat from datanodes -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://dfs-cluster</value>
    </property>

    <!-- write zookeeper management server address; port 2181 -->
   <property>
        <name>ha.zookeeper.quorum</name>
        <value>master-namenode:2181,master-secondary-namenode:2181,worker-datanode:2181</value>
    </property>
</configuration>
```

3) yarn-site.xml ìˆ˜ì •

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master-namenode</value>
    </property>

    <!-- Assistant service for MapReduce Shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>

    <!-- Restrict virtual memory use if memory use is beyond limit: False -->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
     </property>
</configuration>
```

4) mapred-site.xml ìˆ˜ì •

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
</configuration>
```

5) hadoop_env.shì— ì¶”ê°€

```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/root/cluster/hadoop
```

6) ~/cluster/hadoop/etc/hadoop ì•„ë˜ masters íŒŒì¼ê³¼ workersíŒŒì¼ ìƒì„± í›„ ë‚´ìš© ì…ë ¥

- masters (ìƒì„±)

```bash
nano masters
```

```bash
master-namenode
master-secondary-namenode
```

 - í˜¸ìŠ¤íŠ¸ë„¤ì„ ì‘ì„±í•´ì£¼ë©´ ë¨

- workers (ìˆ˜ì •)

```bash
nano workers
```

```bash
worker-datanode
worker-datanode2
```

 - ê¸°ì¡´ì— ìˆì—ˆë˜ localhostëŠ” ì‚­ì œ

> **zookeeper ì„¤ì •**
> 

1) ~/cluster/zookeeper/confë¡œ ì´ë™ í›„ zoo_sample.cfgë¥¼ zoo.cfgë¡œ ë³€ê²½

```bash
cd ~/cluster/zookeeper/conf
mv zoo_sample.cfg zoo.cfg
```

2) .bashrc íŒŒì¼ì— ZOOKEEPER_HOME í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

```bash
echo 'export ZOOKEEPER_HOME=/root/cluster/zookeeper' >> ~/.bashrc
source ~/.bashrc
```

3) zoo.cfg í¸ì§‘

- `2888` : Leaderê°€ Followerì—ê²Œ ì—´ì–´ë†“ì€ ë™ê¸°í™”ìš© í¬íŠ¸
- `3888` : Leaderê°€ ì£½ìœ¼ë©´ Leader ì„ ì¶œì„ ìœ„í•œ í¬íŠ¸
- `clientPort` : Hadoop Client `core-site.xml`
- `dataDir` : Zookeeper Stage, Transaction ë¡œê·¸, etc ê´€ë¦¬

```bash
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
dataDir=/root/cluster/zookeeper/data
dataLogDir=/root/cluster/zookeeper/logs
# the port at which the clients will connect
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
maxSessionTimeout=180000
maxClientCnxns=0

server.1=master-namenode:2888:3888
server.2=master-secondary-namenode:2888:3888
server.3=worker-datanode:2888:3888

#
# Be sure to read the maintenance section of the
# administrator guide before turning on autopurge.
#
# https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1

## Metrics Providers
#
# https://prometheus.io Metrics Exporter
#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider
#metricsProvider.httpHost=0.0.0.0
#metricsProvider.httpPort=7000
#metricsProvider.exportJvmInfo=true
```

 - ì„œë²„ ì„¸ ëŒ€ë¥¼ ì£¼í‚¤í¼ ì•™ìƒë¸”ë¡œ ì„¤ì •.

 - serverë’¤ì— ë“¤ì–´ê°€ëŠ” ìˆ«ì â†’ myid 

â‡’ ì´ê±¸ë¡œ ì„œë²„ ë¶„ê°„

4) myid ì„¤ì •

- zookeeper í´ë” ì•„ë˜ data í´ë” ìƒì„±

```bash
mkdir ~/cluster/zookeeper/data
```

- master namenodeì˜ myidë¥¼ 1ë¡œ ì„¤ì •

```bash
echo 1 > ~/cluster/zookeeper/data/myid
```

 - í›„ì— secondary namenode, worker datanodeì—ë„ ê°ê° 2, 3 ì„¤ì •í•´ì¤„ ì˜ˆì •ì„.

> **ì„¤ì •í•œ ë‚´ìš©ë“¤ì„ ë‹¤ë¥¸ ë…¸ë“œë“¤ì—ê²Œë„ ë³µì‚¬**
> 

1) hadoop ë³µì‚¬

```bash
scp -r ~/cluster/hadoop/etc root@master-secondary-namenode:~/cluster/hadoop/;
scp -r ~/cluster/hadoop/etc root@worker-datanode:~/cluster/hadoop;
scp -r ~/cluster/hadoop/etc root@worker-datanode2:~/cluster/hadoop;
```

 - ë‹¤ë¥¸ ë…¸ë“œë“¤ì— í•˜ë‘¡ì´ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ etc ì•„ë˜ë§Œ ë„£ì–´ì£¼ê¸°

2) zookeeper ë³µì‚¬

```bash
scp -r ~/cluster/zookeeper root@master-secondary-namenode:~/cluster
scp -r ~/cluster/zookeeper root@worker-datanode:~/cluster
```

 - zookeeperë…¸ë“œì— í•´ë‹¹ë˜ëŠ” master secondary name node, data node ë‘ ê°œì—ë§Œ ë³µì‚¬

3) zookeeper ë…¸ë“œë“¤ì—ê²Œ myid ë¶€ì—¬ (ì•„ê¹Œ ëª»í•œ 2, 3 ì„¤ì •)

```bash
ssh master-secondary-namenode 'echo 2 > ~/cluster/zookeeper/data/myid'
ssh worker-datanode 'echo 3 > ~/cluster/zookeeper/data/myid'
```

4) .bashrcì„¤ì •ë„ ë³µì‚¬

```bash
scp -r ~/.bashrc root@master-secondary-namenode:~/
scp -r ~/.bashrc root@worker-datanode:~/
scp -r ~/.bashrc root@worker-datanode2:~/
```

- ë³€ê²½ ë‚´ìš© ì ìš©í•´ì£¼ê¸°

```bash
ssh master-secondary-namenode 'source ~/.bashrc'
ssh worker-datanode 'source ~/.bashrc'
ssh worker-datanode2 'source ~/.bashrc'
```

> **Zookeeper ë°ëª¬ ì‹¤í–‰í•˜ê¸°**
> 

1) zookeeper ë°ëª¬ ì‹¤í–‰í•˜ê¸°

```bash
# START
ssh master-namenode 'cluster/zookeeper/bin/zkServer.sh start';
ssh master-secondary-namenode 'cluster/zookeeper/bin/zkServer.sh start';
ssh worker-datanode 'cluster/zookeeper/bin/zkServer.sh start';

# STATUS
ssh master-namenode 'cluster/zookeeper/bin/zkServer.sh status';
ssh master-secondary-namenode 'cluster/zookeeper/bin/zkServer.sh status';
ssh worker-datanode 'cluster/zookeeper/bin/zkServer.sh status';

# STOP
ssh master-namenode 'cluster/zookeeper/bin/zkServer.sh stop';
ssh master-secondary-namenode 'cluster/zookeeper/bin/zkServer.sh stop';
ssh worker-datanode 'cluster/zookeeper/bin/zkServer.sh stop';
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/11d88c81-e2e8-4e44-930c-ac26939d26e7/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/e010b8e6-5728-4abe-b204-8be1697317c4/Untitled.png)

2) journalnode ì¼œê¸°

```bash
ssh master-namenode '/root/cluster/hadoop/bin/hdfs --daemon start journalnode'
ssh master-secondary-namenode '/root/cluster/hadoop/bin/hdfs --daemon start journalnode'
ssh worker-datanode '/root/cluster/hadoop/bin/hdfs --daemon start journalnode'
```

** jpsë¡œ í™•ì¸

`QuorumPeerMain` : Zookeeper

`JournalNode` : journal node group

í˜¹ì‹œë‚˜ ì˜ ì•ˆë ë• ë¡œê·¸ë¥¼ ì½ì–´ë³´ì

```bash
cat hadoop-root-journalnode-master-namenode.log
```

core-siteì—ì„œ ì´ìƒí•œ ë¬¸ìê°€ ë“¤ì–´ê°”ëŠ”ì§€ UTF-8 íŒŒì‹±ì— ì‹¤íŒ¨í•´ì„œ ì•ˆì¼œì§. ì •ìƒ ë™ì‘ í™•ì¸

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/1e3df61a-aa8d-4091-93c8-2c1ba1cd69dc/Untitled.png)

3) zookeeper ì´ˆê¸°í™”

- zkfc ì„¸íŒ… ì „ì— í•´ì¤˜ì•¼ í•  ì‘ì—….

```bash
hdfs zkfc -formatZK
```

4) zookeeper cli ì ‘ì†

```bash
~/cluster/zookeeper/bin/zkCli.sh

> ls /hadoop-ha
> quit
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/ddf68ff8-08bd-4ba4-9ac1-a701a55abeae/Untitled.png)

ë‚´ê°€ ì•ì„œ ì§€ì •í•œ ë„¤ì„ì„œë¹„ìŠ¤ idê°€ ë‚˜ì˜¤ë©´ ì •ìƒë™ì‘

> **Hadoop ë°ëª¬ ì‹¤í–‰í•˜ê¸°**
> 

1) ë„¤ì„ë…¸ë“œ í¬ë§·

```bash
hdfs namenode -format
```

2) ë„¤ì„ë…¸ë“œ ì‹œì‘

```bash
hdfs --daemon start namenode
```

** jpsë¡œ í™•ì¸

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/31c8e358-1270-45cc-b90e-b5386e8d24e1/Untitled.png)

3) hdfs ì»¨íŠ¸ë¡¤ëŸ¬ í‚¤ê¸° (zookeeper failover controller)

```bash
hdfs --daemon start zkfc
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/49a1d631-e52e-4598-9125-05989b7fd1ba/Untitled.png)

4) master-secondary-namenodeë¥¼  standby nodeë¡œ ì§€ì •

- ìŠ¤íƒ ë°”ì´í•  ë„¤ì„ë…¸ë“œë¡œ ì ‘ì†

```bash
ssh master-secondary-namenode
```

```bash
hdfs namenode -bootstrapStandby
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/0bfb1b5c-f999-4932-9eef-cd9c6254324e/Untitled.png)

5) namenode ì‹œì‘

```bash
hdfs --daemon start namenode
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/3d9412ee-35e9-423f-a0cd-ad0a94e0dc53/Untitled.png)

6) zkfc í‚¤ê¸°

```bash
hdfs --daemon start zkfc
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/8b56278b-cd72-4954-bcf9-dd9ae87e2a97/Untitled.png)

** í™•ì¸

```bash
hdfs haadmin -getServiceState namenode1
hdfs haadmin -getServiceState namenode2

hdfs haadmin -getAllServiceState
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/e3744485-8f80-4726-ae35-e6f3939f4092/Untitled.png)

7) ëª¨ë“  ë…¸ë“œì˜ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ í‚¤ê¸°

```bash
start-dfs.sh
```

### **ğŸ’¢ Trouble Shooting - daemon ì‹¤í–‰**

<aside>
ğŸ’¡ **Attempting to operate on hdfs namenode as root
but there is no HDFS_NAMENODE_USER defined. Aborting operation.**

</aside>

í•˜ë‘¡ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë³´ì•ˆì„ ìœ„í•´ì„œ ì‚¬ìš©ìë¥¼ ë§Œë“¤ì–´ì„œ ì‹¤í–‰í•˜ê¸°ë¥¼ ê¶Œì¥í•¨.

ê·¸ë˜ì„œ ì›ë˜ ì‚¬ìš©ì ê³„ì •ì—ì„œ í•  ë•ŒëŠ” ë”°ë¡œ ì§€ì •í•´ì£¼ì§€ ì•Šì•„ë„ ë¨.

í•˜ì§€ë§Œ í¸ì˜ ìƒ ë£¨íŠ¸ ê³„ì •ì—ì„œ ì§„í–‰í•˜ë¯€ë¡œ ì¶”ê°€ë¡œ ì„¤ì •í•´ì£¼ì–´ì•¼í•¨.

í•˜ë‘¡ í™ˆ ë””ë ‰í† ë¦¬ì—ì„œ [hadoop-env.sh](http://hadoop-env.sh) íŒŒì¼ì„ ì—´ê³  ì•„ë˜ í–‰ì„ ì¶”ê°€

```bash
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_JOURNALNODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
export HDFS_ZKFC_USER=root
```

** jps í™•ì¸

```bash
ssh master-namenode jps; echo '========='; ssh master-secondary-namenode jps; echo '========='; ssh worker-datanode jps; echo '========='; ssh worker-datanode2 jps;
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/04badf7d-bbe3-427c-99e1-416286f5cd21/Untitled.png)

8) yarn ì‹¤í–‰

```bash
start-yarn.sh
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/7df7bddb-6bb1-4eb5-8c2a-a56a7040863c/Untitled.png)

<aside>
ğŸ’¡ **ì •ë¦¬**

ë„¤ì„ë…¸ë“œ â†’ `ResourceManager` (Activeë§Œ), `Namenode`

ë°ì´í„°ë…¸ë“œ â†’ `NodeManager`, `DataNode`
Journal group â†’ `JournalNode`

Active, Standby Node (Failover) â†’ `DFSZFailoverController` 

Zookeeper ë…¸ë“œë“¤ â†’ `QuorumPeerMain`

</aside>

> **Hadoop ë°ëª¨ í…ŒìŠ¤íŠ¸**
> 

1) job history server í‚¤ê¸°(ì„ íƒ)

```bash
mapred --daemon start historyserver
```

2) health check(ì„ íƒ)

```bash
hdfs dfsadmin -report
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/359ded2e-213b-4a7b-a612-2dddd8ea4e0e/Untitled.png)

 - ì˜ ì‚´ì•„ìˆëŠ” ìš°ë¦¬ ë°ì´í„°ë…¸ë“œë“¤

3) í´ë” ìƒì„± ë° íŒŒì¼ ì ì¬

```bash
hdfs dfs -mkdir /example
```

```bash
hdfs dfs -put ~/cluster/hadoop/README.txt /example/input.txt
```

4) ë§µë¦¬ë“€ìŠ¤ ì˜ˆì œ ì½”ë“œ ì‹¤í–‰

```bash
yarn jar ~/cluster/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar wordcount /example/input.txt /example/output
```

5) í™•ì¸

- Reducerê°€ í•œ ê°œë¡œ ì§€ì •ë˜ì–´ ìˆì–´ì„œ 00000 í•˜ë‚˜ ë¿ì„

```bash
hdfs dfs -ls /example/output
```

```bash
hdfs dfs -cat /example/output/part-r-00000
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/8dc40c2c-6227-4eee-b4ca-c3025d920a92/Untitled.png)

> **Web UI í…ŒìŠ¤íŠ¸**
> 

1) public IP í™•ì¸

```bash
curl ifconfig.me
```

2) namenodeì— ì ‘ì†í•´ë³´ê¸°

```bash
ë¸Œë¼ìš°ì €ì— 3.35.216.47:50070
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/ef9ce3ed-bd34-4c12-b7d9-b4c25448c066/Untitled.png)

### **ğŸ’¢** Trouble Shooting

ì–´â€¦ ê·¼ë° ì•½ê°„ì˜ ë¬¸ì œâ€¦

ë„ì»¤ ì»¨í…Œì´ë„ˆë“¤ì´ í˜¸ìŠ¤íŠ¸ì˜ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê³µìœ í•˜ëŠ” ë°”ëŒì— ì €ê±° í•˜ë‚˜ë¡œë°–ì— ì ‘ì† ëª»í•¨..

ìƒê´€ì€ ì—†ì§€ë§Œ ë‹¤ë¥¸ ë…¸ë“œë“¤ í™•ì¸ì´ ë¶ˆê°€â€¦

ë­”ê°€ í¬íŠ¸ë¥¼ zookeeprì²˜ëŸ¼ ë‹¤ë¥´ê²Œ ì§€ì •í–ˆì–´ì•¼ ëì„..ì§€ë„?

50070:50070, 50071:50070 ì´ëŸ°ì‹ìœ¼ë¡œ

ê·¼ë° ì‚¬ì‹¤ ì¼ë‹¨ ë§ˆìŠ¤í„°ë…¸ë“œë§Œ ë³´ì´ë©´ ë‹¤ë¼ì„œ, ê·¸ëƒ¥ ì•ˆí•  ì˜ˆì • ã…‹

ë” ì´ìƒì˜ ê°ˆì•„ì—ê¸°ë€.. ë¶ˆê°€.. ã…‹

3) yarnì— ì ‘ì†í•´ë³´ê¸°

```bash
ë¸Œë¼ìš°ì €ì— 3.35.216.47:8088
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/913f9852-3183-474b-baa7-58847209ca58/Untitled.png)

> **Spark ì„¸íŒ…**
> 

1) spark-env.shë¥¼ ìˆ˜ì •í•˜ëŸ¬ ì´ë™

```bash
cd ~/cluster/spark/conf
```

2) spark-env íŒŒì¼ ì´ë¦„ ìˆ˜ì •

```bash
mv spark-env.sh.template spark-env.sh
```

3) [spark-env.sh](http://spark-env.sh)ì— ì¶”ê°€

```bash
export SPARK_HOME=/root/cluster/spark
export SPARK_CONF_DIR=/root/cluster/spark/conf
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/root/cluster/hadoop
export HADOOP_CONF_DIR=/root/cluster/hadoop/etc/hadoop
export SPARK_MASTER_WEBUI_PORT=18080
```

4) spark-defaults.conf íŒŒì¼ ì´ë¦„ ìˆ˜ì •

```bash
mv spark-deaults.conf.template spark-defaults.conf
```

5) spark-defaults.confì— ì¶”ê°€

```bash
spark.master    yarn
spark.eventLog.enabled  true
spark.eventLog.dir      /root/cluster/spark/logs
```

6) workers íŒŒì¼ ì´ë¦„ ìˆ˜ì •

```bash
mv workers.template workers
```

7) workersì— [localhost](http://localhost) ì§€ìš°ê³  ë°ì´í„°ë…¸ë“œë“¤ ë“±ë¡

```bash
worker-datanode
worker-datanode2
```

8) .bashrcì— ì¶”ê°€

```bash
export PYTHONPATH=/usr/bin/python3
export PYSPARK_PYTHON=/usr/bin/python3

# ì ìš©
source ~/.bashrc
```

- ë‹¤ë¥¸ ë…¸ë“œë“¤ì—ë„ ë³µì‚¬

```bash
scp -r ~/.bashrc root@master-secondary-namenode:~/
scp -r ~/.bashrc root@worker-datanode:~/
scp -r ~/.bashrc root@worker-datanode2:~/

# ì ìš©
ssh master-secondary-namenode 'source ~/.bashrc'
ssh worker-datanode 'source ~/.bashrc'
ssh worker-datanode2 'source ~/.bashrc'
```

9) ìŠ¤íŒŒí¬ ì„¤ì • ë‹¤ë¥¸ ê³³ì—ë„ ë³µì‚¬

- ëª¨ë“  ë§ˆìŠ¤í„°ì™€ ì›Œì»¤ë“¤ì—ê²Œ ë³´ë‚´ê¸°

```bash
scp -r ~/cluster/spark root@master-secondary-namenode:~/cluster
scp -r ~/cluster/spark root@worker-datanode:~/cluster
scp -r ~/cluster/spark root@worker-datanode2:~/cluster
```

> **Spark ë°ëª¬ ì‹¤í–‰**
> 

1) cluster/spark/sbin ì•„ë˜ ìˆëŠ” [start-all.sh](http://start-all.sh) ì‹¤í–‰

```bash
cd ~/cluster/spark/sbin
./start-all.sh
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/ffac1e32-6f9b-498f-8801-e604fa076183/Untitled.png)

 - Master, Workerê°€ ì¶”ê°€ë¡œ í‘œì‹œëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

 - ë§Œì•½ ì•ˆ ì¼œì§€ë©´ [stop-all.sh](http://stop-all.sh) í•˜ê³  ë‹¤ì‹œ í‚¤ë©´ ë¨

** ë¸Œë¼ìš°ì €ì—ì„œë„ í™•ì¸

```bash
ë¸Œë¼ìš°ì €ì— http://3.35.216.47:18080/ ì…ë ¥
```

2) spark submit ì‹¤í–‰

```bash
cd ~/cluster/spark/bin
spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster --driver-memory 512m --executor-memory 512m --executor-cores 1 $SPARK_HOME/examples/jars/spark-examples_*.jar 5
```

 - master : yarn-cluster-manager

 (ë¡œì»¬ëª¨ë“œ â†’ local, ìŠ¤íŒŒí¬ì—ì„œ ì œê³µí•˜ëŠ” standalone-cluster â†’ spark-masterhost report)

ê´€ë ¨ ë ˆí¼ëŸ°ìŠ¤: https://spark.apache.org/docs/latest/submitting-applications.html

 - deploy mode : cluster mode

 - driver ê°œìˆ˜: 512ê°œ

 - ì½”ì–´ ê°œìˆ˜: 1ê°œ

 - ì‘ì—… : spark-examplesì—ì„œ ì£¼ëŠ” íŒŒì¼

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/cdf3bcfd-c74f-4d1d-a1ce-4158ad6590af/Untitled.png)

yarnì´ ìˆ˜í–‰í–ˆê¸° ë•Œë¬¸ì— yarn(8088)ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ ë³´ë©´

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/f09a8094-dc65-4f5a-acff-52b7fa18441a/Untitled.png)

> **Automatic Failover on HDFS Cluster**
> 

kill -9 ë¥¼ ì´ìš©í•´ì„œ Active nodeì˜ Namenodeë¥¼ ì£½ì´ë©´, Standbyë…¸ë“œê°€ Activeë¡œ ì „í™˜ë¨.

ê·¸ë¦¬ê³  mapred jobì„ ì‹¤í–‰ì‹œí‚¤ë©´ ìƒˆë¡œìš´ Active nodeì—ì„œ ì‹¤í–‰ë¨.

- ì „í™˜ëœ ëª¨ìŠµ

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/b729c067-66de-41a6-88dd-24be4ee5ad2a/Untitled.png)

- secondaryì—ì„œ ì •ìƒ ì‹¤í–‰

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/d76a30d0-0560-4722-8a8d-d89838d3b33a/Untitled.png)

> **Zeppelin ì„¤ì • ì„¸íŒ…ê³¼ ë°ëª¬ ì‹¤í–‰**
> 

1) (ì´ë¯¸ ê¹”ê³  ì••ì¶•ì„ í•´ì œí–ˆë‹¤ë©´) .bashrcì— í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

```bash
export ZEPPELIN_HOME=~/cluster/zeppelin

# ì ìš©
source ~/.bashrc
```

2) zeppelin-site.xml íŒŒì¼ ì´ë¦„ ë³€ê²½

```bash
cd ~/cluster/zeppelin/conf
mv zeppelin-site.xml.template zeppelin-site.xml
```

3) zeppelin-site.xmlì— ì¶”ê°€

```xml
<property>
  <name>zeppelin.server.addr</name>
  <value>0.0.0.0</value>
  <description>Server binding address</description>
</property>

<property>
  <name>zeppelin.server.port</name>
  <value>18888</value>
  <description>Server port.</description>
</property>
```

 - 18888 OR Up to Your Preference

4) [zeppelin-env.sh](http://zeppelin-env.sh) íŒŒì¼ ì´ë¦„ ë³€ê²½

```xml
mv zeppelin-env.sh.template zeppelin-env.sh
```

5) [zeppelin-env.sh](http://zeppelin-env.sh) íŒŒì¼ì— ì¶”ê°€

- í”„ë ˆì„ì›Œí¬ ì„¤ì •

```bash
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

export HADOOP_HOME=/root/cluster/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

export SPARK_HOME=/root/cluster/spark
export SPARK_MASTER=yarn
export ZEPPELIN_PORT=18888

export PYTHONPATH=/usr/bin/python3
export PYSPARK_PYTHON=/usr/bin/python3
export PYSPARK_DRIVER_PYTHON=/usr/bin/python3
```

 - zeppelinì€ ë‹¤ë¥¸ ë…¸ë“œì— ë³µì‚¬í•  í•„ìš” ì—†ìŒ.

6) zeppelin ë°ëª¬ ì‹œì‘

```bash
cd ~/cluster/zeppelin/bin
./zeppelin-daemon.sh start
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/d7e3ba55-11e3-4216-bb2e-fb6d4ef6300c/Untitled.png)

7) ë¸Œë¼ìš°ì €ë¡œ ì œí”Œë¦° ì„œë²„ ì ‘ì†

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/3f9f6346-2be4-44e1-8b45-c5e48261f81b/Untitled.png)

8) ì¶”ê°€ ì„¸íŒ…

- ì¸í„°í”„ë¦¬í„° ì ‘ì†

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/f494f864-5f10-44e4-9814-6ed01bb3964a/Untitled.png)

- Spark ê²€ìƒ‰ í›„ Edit í´ë¦­

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/757b160d-ea92-4052-90f8-223dc1efd79b/Untitled.png)

- ì¶”ê°€ë¡œ ë³€ê²½í•œ ë¶€ë¶„

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/46e2b7bb-93ae-4c09-8737-62f1f87079a8/Untitled.png)

 - í™˜ê²½ì— ë§ì¶° ììœ ë¡­ê²Œ ë°”ê¾¸ë©´ ë¨.

** ì¹´ì‚°ë“œë¼ ì»¤ë„¥í„° ì¶”ê°€

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/a6e8c770-339c-4a6a-bd08-6ed247c63987/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/bb008ff3-ac32-4ff7-a5bd-9dd0cde58cb8/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/0e6da90a-d14f-40de-8654-a589cd07821f/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/f9390503-d758-4064-a15f-595c7339a80a/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/add1b271-1e45-44bc-8f8f-f15b7fc5fae8/Untitled.png)

- Save > Ok
    
    â‡’ ì•Œì•„ì„œ restart í•´ì¤Œ
    
- Home > Notebook > Create new note

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/9c8432e2-36f2-4be1-badb-40765f995eb1/Untitled.png)

### **ğŸ’¢** Trouble Shooting

ìˆ˜ë§ì€ ì¬ì‹œì‘ìœ¼ë¡œ ì¸í•´â€¦ ê°‘ìê¸° **Interpreter is not preccessing. Connect timeout ì˜¤ë¥˜ê°€ ëœ¬ë‹¤ë©´! ìŠ¤íŒŒí¬ì™€ ì œí”Œë¦° ìƒì— ì—°ê²°ì´ ëŠì–´ì§„ ê²ƒì´ë‹¤.**

- ì—ëŸ¬ì½”ë“œ
    
    ```python
    org.apache.zeppelin.interpreter.InterpreterException: java.io.IOException: Interpreter process is not running
    Interpreter download command: /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Dfile.encoding=UTF-8 -Dlog4j.configuration=log4j_yarn_cluster.properties -Dzeppelin.log.file=/root/cluster/zeppelin/logs/zeppelin-interpreter-spark-shared_process--master-namenode.log -cp :/root/cluster/zeppelin/interpreter/spark/*:::/root/cluster/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.1.jar:/root/cluster/zeppelin/interpreter/spark/spark-interpreter-0.10.1.jar:/root/cluster/hadoop/etc/hadoop org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader 172.21.0.2 45091 spark /root/cluster/zeppelin/local-repo/spark
    log4j:WARN No appenders could be found for logger (org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader).
    log4j:WARN Please initialize the log4j system properly.
    log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
    [INFO] Interpreter launch command: /root/cluster/spark/bin/spark-submit --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer --driver-java-options  -Dfile.encoding=UTF-8 -Dlog4j.configuration=log4j_yarn_cluster.properties -Dzeppelin.log.file=/root/cluster/zeppelin/logs/zeppelin-interpreter-spark-shared_process--master-namenode.log --conf spark.yarn.dist.archives=/root/cluster/spark/R/lib/sparkr.zip#sparkr --conf spark.yarn.isPython=true --conf spark.executor.instances=3 --conf spark.app.name=spark-shared_process --conf spark.webui.yarn.useProxy=false --conf spark.driver.cores=1 --conf spark.yarn.maxAppAttempts=1 --conf spark.executor.memory=1g --conf spark.master=yarn --conf spark.files=/root/cluster/zeppelin/conf/log4j_yarn_cluster.properties --conf spark.driver.memory=1g --conf spark.jars=/root/cluster/zeppelin/local-repo/spark/spotbugs-annotations-3.1.12.jar,/root/cluster/zeppelin/local-repo/spark/slf4j-api-1.7.26.jar,/root/cluster/zeppelin/local-repo/spark/config-1.3.4.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-core-shaded-4.7.2.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-mapper-runtime-4.7.2.jar,/root/cluster/zeppelin/local-repo/spark/spark-cassandra-connector-driver_2.12-3.0.0.jar,/root/cluster/zeppelin/local-repo/spark/scala-reflect-2.12.11.jar,/root/cluster/zeppelin/local-repo/spark/jsr305-3.0.2.jar,/root/cluster/zeppelin/local-repo/spark/paranamer-2.8.jar,/root/cluster/zeppelin/local-repo/spark/spark-cassandra-connector_2.12-3.0.0.jar,/root/cluster/zeppelin/local-repo/spark/jcip-annotations-1.0-1.jar,/root/cluster/zeppelin/local-repo/spark/native-protocol-1.4.10.jar,/root/cluster/zeppelin/local-repo/spark/metrics-core-4.0.5.jar,/root/cluster/zeppelin/local-repo/spark/javatuples-1.2.jar,/root/cluster/zeppelin/local-repo/spark/commons-lang3-3.9.jar,/root/cluster/zeppelin/local-repo/spark/scala-library-2.12.11.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-query-builder-4.7.2.jar,/root/cluster/zeppelin/local-repo/spark/HdrHistogram-2.1.11.jar,/root/cluster/zeppelin/local-repo/spark/reactive-streams-1.0.2.jar,/root/cluster/zeppelin/interpreter/spark/scala-2.12/spark-scala-2.12-0.10.1.jar,/root/cluster/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.1.jar --conf spark.executor.cores=1 --conf spark.submit.deployMode=cluster --conf spark.yarn.submit.waitAppCompletion=false /root/cluster/zeppelin/interpreter/spark/spark-interpreter-0.10.1.jar 172.21.0.2 45091 spark-shared_process :
    2024-04-03 00:46:05,638 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    2024-04-03 00:46:06,221 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master-namenode/172.21.0.2:8032
    2024-04-03 00:46:07,642 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:08,643 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:09,644 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:10,644 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:11,645 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:12,646 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:13,646 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:14,647 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:15,648 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:16,649 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:17,657 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:18,658 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:19,659 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:20,659 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:21,660 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:22,661 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:23,661 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:24,662 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:25,663 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:26,663 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:26,665 INFO retry.RetryInvocationHandler: java.net.ConnectException: Call From master-namenode/172.21.0.2 to master-namenode:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationClientProtocolPBClientImpl.getClusterMetrics over null after 1 failover attempts. Trying to failover after sleeping for 26075ms.
    2024-04-03 00:46:53,741 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:54,741 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:55,742 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:56,743 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:57,744 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:58,744 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:59,745 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:00,746 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:01,746 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:02,747 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:02,748 INFO retry.RetryInvocationHandler: java.net.ConnectException: Call From master-namenode/172.21.0.2 to master-namenode:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationClientProtocolPBClientImpl.getClusterMetrics over null after 2 failover attempts. Trying to failover after sleeping for 41946ms.
    
    	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:129)
    	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.getFormType(RemoteInterpreter.java:271)
    	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:438)
    	at org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:69)
    	at org.apache.zeppelin.scheduler.Job.run(Job.java:172)
    	at org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)
    	at org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:182)
    	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
    	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    	at java.lang.Thread.run(Thread.java:750)
    Caused by: java.io.IOException: Interpreter process is not running
    Interpreter download command: /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Dfile.encoding=UTF-8 -Dlog4j.configuration=log4j_yarn_cluster.properties -Dzeppelin.log.file=/root/cluster/zeppelin/logs/zeppelin-interpreter-spark-shared_process--master-namenode.log -cp :/root/cluster/zeppelin/interpreter/spark/*:::/root/cluster/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.1.jar:/root/cluster/zeppelin/interpreter/spark/spark-interpreter-0.10.1.jar:/root/cluster/hadoop/etc/hadoop org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader 172.21.0.2 45091 spark /root/cluster/zeppelin/local-repo/spark
    log4j:WARN No appenders could be found for logger (org.apache.zeppelin.interpreter.remote.RemoteInterpreterDownloader).
    log4j:WARN Please initialize the log4j system properly.
    log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
    [INFO] Interpreter launch command: /root/cluster/spark/bin/spark-submit --class org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer --driver-java-options  -Dfile.encoding=UTF-8 -Dlog4j.configuration=log4j_yarn_cluster.properties -Dzeppelin.log.file=/root/cluster/zeppelin/logs/zeppelin-interpreter-spark-shared_process--master-namenode.log --conf spark.yarn.dist.archives=/root/cluster/spark/R/lib/sparkr.zip#sparkr --conf spark.yarn.isPython=true --conf spark.executor.instances=3 --conf spark.app.name=spark-shared_process --conf spark.webui.yarn.useProxy=false --conf spark.driver.cores=1 --conf spark.yarn.maxAppAttempts=1 --conf spark.executor.memory=1g --conf spark.master=yarn --conf spark.files=/root/cluster/zeppelin/conf/log4j_yarn_cluster.properties --conf spark.driver.memory=1g --conf spark.jars=/root/cluster/zeppelin/local-repo/spark/spotbugs-annotations-3.1.12.jar,/root/cluster/zeppelin/local-repo/spark/slf4j-api-1.7.26.jar,/root/cluster/zeppelin/local-repo/spark/config-1.3.4.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-core-shaded-4.7.2.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-mapper-runtime-4.7.2.jar,/root/cluster/zeppelin/local-repo/spark/spark-cassandra-connector-driver_2.12-3.0.0.jar,/root/cluster/zeppelin/local-repo/spark/scala-reflect-2.12.11.jar,/root/cluster/zeppelin/local-repo/spark/jsr305-3.0.2.jar,/root/cluster/zeppelin/local-repo/spark/paranamer-2.8.jar,/root/cluster/zeppelin/local-repo/spark/spark-cassandra-connector_2.12-3.0.0.jar,/root/cluster/zeppelin/local-repo/spark/jcip-annotations-1.0-1.jar,/root/cluster/zeppelin/local-repo/spark/native-protocol-1.4.10.jar,/root/cluster/zeppelin/local-repo/spark/metrics-core-4.0.5.jar,/root/cluster/zeppelin/local-repo/spark/javatuples-1.2.jar,/root/cluster/zeppelin/local-repo/spark/commons-lang3-3.9.jar,/root/cluster/zeppelin/local-repo/spark/scala-library-2.12.11.jar,/root/cluster/zeppelin/local-repo/spark/java-driver-query-builder-4.7.2.jar,/root/cluster/zeppelin/local-repo/spark/HdrHistogram-2.1.11.jar,/root/cluster/zeppelin/local-repo/spark/reactive-streams-1.0.2.jar,/root/cluster/zeppelin/interpreter/spark/scala-2.12/spark-scala-2.12-0.10.1.jar,/root/cluster/zeppelin/interpreter/zeppelin-interpreter-shaded-0.10.1.jar --conf spark.executor.cores=1 --conf spark.submit.deployMode=cluster --conf spark.yarn.submit.waitAppCompletion=false /root/cluster/zeppelin/interpreter/spark/spark-interpreter-0.10.1.jar 172.21.0.2 45091 spark-shared_process :
    2024-04-03 00:46:05,638 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    2024-04-03 00:46:06,221 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at master-namenode/172.21.0.2:8032
    2024-04-03 00:46:07,642 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:08,643 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:09,644 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:10,644 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:11,645 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:12,646 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:13,646 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:14,647 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:15,648 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:16,649 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:17,657 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:18,658 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:19,659 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:20,659 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:21,660 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:22,661 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:23,661 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:24,662 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:25,663 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:26,663 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:26,665 INFO retry.RetryInvocationHandler: java.net.ConnectException: Call From master-namenode/172.21.0.2 to master-namenode:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationClientProtocolPBClientImpl.getClusterMetrics over null after 1 failover attempts. Trying to failover after sleeping for 26075ms.
    2024-04-03 00:46:53,741 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:54,741 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:55,742 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:56,743 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:57,744 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:58,744 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:46:59,745 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:00,746 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:01,746 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:02,747 INFO ipc.Client: Retrying connect to server: master-namenode/172.21.0.2:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
    2024-04-03 00:47:02,748 INFO retry.RetryInvocationHandler: java.net.ConnectException: Call From master-namenode/172.21.0.2 to master-namenode:8032 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking ApplicationClientProtocolPBClientImpl.getClusterMetrics over null after 2 failover attempts. Trying to failover after sleeping for 41946ms.
    
    	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.internal_create(RemoteInterpreter.java:157)
    	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:126)
    	... 13 more
    ```
    

1) Spark Interpreterë¥¼ ì¬ì‹œì‘í•´ë³´ê¸° - ì›¹ ìƒì—ì„œ ê°€ëŠ¥

2) ì•ˆëœë‹¤ë©´, zeppelinì—ì„œ `zepeelin-daemon.sh restart`ë¥¼ ì‚¬ìš©í•´ì„œ ì œí”Œë¦° ì¬ì‹¤í–‰

3) ê·¸ë˜ë„ ì•ˆëœë‹¤ë©´, ë¡œê·¸ë¥¼ í™•ì¸

â‡’ 8032ëŠ” yarn-site.xmlì—ì„œ ë”°ë¡œ hostnameë§Œ ì§€ì •í•˜ê³  í¬íŠ¸ë¥¼ ì§€ì •í•˜ì§€ ì•Šì•˜ì„ë•Œ ë‚˜ì˜¤ëŠ” ë””í´íŠ¸ê°’ì„
ì´ ë””í´íŠ¸ ê°’ë„ ì˜ ì•ˆë˜ëŠ” ê±°ë¼ë©´, ê·¸ëƒ¥ resource manager ì¬ì‹¤í–‰

```python
2024-04-03 00:47:02,748 INFO retry.RetryInvocationHandler: java.net.ConnectException: Call From master-namenode/172.21.0.2 to master-namenode:8032 failed on connection exception: java.net.Connec>

        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.internal_create(RemoteInterpreter.java:157)
        at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.open(RemoteInterpreter.java:126)
        ... 13 more

```

4) `[stop-yarn.sh](http://stop-yarn.sh)` and `start-yarn.sh`

í˜¹ì€ ë‚˜ëŠ” ê·¸ëƒ¥ ëª¨ë‘ë¥¼ ê»ë‹¤ ì¼°ë‹¤. (`stop-all.sh` and `start-all.sh`)

> **CSV íŒŒì¼ ì—…ë¡œë“œ**
> 

1) bashë¥¼ ì—´ì–´ì„œ ec2ë¡œ ë³µì‚¬

```bash
scp -i <private key> <csv data> ubuntu@<domain>:~
```

2) docker containerë¡œ ë³µì‚¬

```bash
sudo docker cp card-data_201909.csv master-namenode:/root/cluster
```

3) hdfsë¡œ ë³µì‚¬

```bash
hdfs dfs -put card-data_201909.csv /example/card_201909.csv
```

> **Cassandra ì—°ê²°**
> 

1) ì¹´ì‚°ë“œë¼ìš© ìƒˆë¡œìš´ ì»¨í…Œì´ë„ˆ ìƒì„±

```bash
sudo docker run -i -d --network d110-network --hostname cassandra-db --name cassandra-db -p 9042:9042 ubuntu:20.04
```

 - spark, zeppelinê³¼ ê°™ì€ ë„¤íŠ¸ì›Œí¬ì— ì—°ê²°ë˜ì–´ ìˆì–´ì•¼í•¨.

 - ì–´ì°¨í”¼ ë‚´ë¶€ì—ì„œ ë„ì»¤ ì»¨í…Œì´ë„ˆë“¤ë¼ë¦¬ í†µì‹ í•˜ëŠ”ê±°ë¼ í¬íŠ¸ í¬ì›Œë”©ì´ í•„ìš”ì—†ì§€ë§Œ ìŠ¤í”„ë§ ë¶€íŠ¸ì™€ì˜ ì—°ê²°ì„ ìœ„í•´ í¬íŠ¸ ì§€ì •

2) ì¹´ì‚°ë“œë¼ ë‹¤ìš´ë¡œë“œ

```bash
wget https://archive.apache.org/dist/cassandra/4.1.4/apache-cassandra-4.1.4-bin.tar.gz
```

3) ì••ì¶•í•´ì œ

```bash
tar -xzvf <ë‹¤ìš´ë°›ì€ cassandra íŒŒì¼>
```

4) cassandra.yaml íŒŒì¼ ìˆ˜ì •

```bash
seed_provider:
  # Addresses of hosts that are deemed contact points.
  # Cassandra nodes use this list of hosts to find each other and learn
  # the topology of the ring.  You must change this if you are running
  # multiple nodes!
  - class_name: org.apache.cassandra.locator.SimpleSeedProvider
    parameters:
      # seeds is actually a comma-delimited list of addresses.
      # Ex: "<ip1>,<ip2>,<ip3>"
      - seeds: "<ì»¨í…Œì´ë„ˆ ì£¼ì†Œ>:7000"

listen_address=<ì»¨í…Œì´ë„ˆ ì£¼ì†Œ>
rpc_address=<ì»¨í…Œì´ë„ˆ ì£¼ì†Œ>
```

5) spark-default.conf ìˆ˜ì • (ì•„ë˜ ë‚´ìš©ì„ ì¶”ê°€)

```bash
spark.cassandra.connection.host 172.21.0.6
spark.cassandra.connection.port 9042
```

6) zeppelinì—ì„œ ì„¤ì • ë³€ê²½

- spark interpreterì—ì„œ edit â†’ connector ì„¤ì •(datastaxì—ì„œ ë‚˜ì˜¨ driver)
- cassandra interpreter

7) cassandra db ì‹¤í–‰

```bash
cd ~/cassandra/bin
./cassandra -f
```

 - -f ì˜µì…˜ : í¬ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰

 - -R : rootê¶Œí•œ ì‹¤í–‰ì„ ê¶Œì¥í•˜ì§€ ì•ŠëŠ”ë°, ê·¸ë˜ë„ í•´ì•¼ê² ë‹¤ë©´ ì´ ì˜µì…˜ì„ ì¶”ê°€

> **Cassandraì—ì„œ Keyspace(database) ë° í…Œì´ë¸” ìƒì„±**
> 

1) cqlsh ì ‘ì†

```bash
./cqlsh
# ì•ˆëœë‹¤ë©´(ìê¾¸ ë¡œì»¬ë¡œ ì ‘ì†í•œë‹¤ë©´)
./cqlsh <ipì£¼ì†Œ> <port:9042>
```

2) key space ìƒì„±

```bash
CREATE KEYSPACE trend WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': 3} AND durable_writes = true;
```

- keyspace (ì˜µì…˜)ì‘ì„± ìš”ë ¹
    
    ### **1. ëª…í™•í•œ ëª…ëª… ê·œì¹™ ì‚¬ìš©**
    
    - Keyspace ì´ë¦„ì€ ëª©ì ì´ë‚˜ í”„ë¡œì íŠ¸ ì´ë¦„ì„ ë°˜ì˜í•´ì•¼ í•˜ë©°, ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‰½ê²Œ ì‹ë³„í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    - ì¼ê´€ëœ ëª…ëª… ê·œì¹™ì„ ì‚¬ìš©í•˜ë©´ íŒ€ ë‚´ì—ì„œ í˜¼ë€ì„ ì¤„ì´ê³ , ê´€ë¦¬ë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.
    
    ### **2. ë³µì œ ì „ëµ ì„ íƒ**
    
    - **SimpleStrategy**: ê°œë°œ í™˜ê²½ì´ë‚˜ ë‹¨ì¼ ë°ì´í„° ì„¼í„° í™˜ê²½ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. ë³µì œ íŒ©í„°(Replication Factor, RF)ë§Œ ì§€ì •í•©ë‹ˆë‹¤. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ì‚¬ìš©ì„ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - **NetworkTopologyStrategy**: ìš´ì˜ í™˜ê²½ì´ë‚˜ ì—¬ëŸ¬ ë°ì´í„° ì„¼í„°ë¥¼ ê°€ì§„ ê²½ìš°ì— ì‚¬ìš©ë©ë‹ˆë‹¤. ë°ì´í„° ì„¼í„°ë³„ë¡œ ë³µì œ íŒ©í„°ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°, ë” ì„¸ë°€í•œ ì œì–´ì™€ ë†’ì€ ê°€ìš©ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ### **3. ì ì ˆí•œ ë³µì œ íŒ©í„° ì„¤ì •**
    
    - ë³µì œ íŒ©í„°(RF)ëŠ” ë°ì´í„°ì˜ ê°€ìš©ì„±ê³¼ ë‚´êµ¬ì„±ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. RFë¥¼ ë„ˆë¬´ ë‚®ê²Œ ì„¤ì •í•˜ë©´ ë°ì´í„° ì†ì‹¤ì˜ ìœ„í—˜ì´ ì¦ê°€í•˜ê³ , ë„ˆë¬´ ë†’ê²Œ ì„¤ì •í•˜ë©´ ë¶ˆí•„ìš”í•œ ì €ì¥ ê³µê°„ ì‚¬ìš©ê³¼ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ì¼ë°˜ì ìœ¼ë¡œ RFëŠ” 3ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„°ì˜ ì†ì‹¤ ì—†ì´ ë…¸ë“œ ì¥ì• ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ì¶œë°œì ì…ë‹ˆë‹¤.
    
    ### **4. í‚¤ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì‹œ ì˜µì…˜ ê³ ë ¤**
    
    - **DURABLE_WRITES**: ì´ ì˜µì…˜ì€ ë°ì´í„°ì˜ ë‚´êµ¬ì„±ì„ ì œì–´í•©ë‹ˆë‹¤. **`true`**ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  ì“°ê¸° ì‘ì—…ì´ ì»¤ë°‹ ë¡œê·¸ì— ê¸°ë¡ë©ë‹ˆë‹¤. íŠ¹ì •í•œ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ ëŠ” ëŒ€ë¶€ë¶„ **`true`**ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    - **REPLICATION**: ì—¬ê¸°ì— ë³µì œ ì „ëµê³¼ ë³µì œ íŒ©í„°ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì „ëµê³¼ íŒ©í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    
    ### **5. CQL ì‚¬ìš© ì˜ˆ**
    
    ì•„ë˜ëŠ” **`NetworkTopologyStrategy`**ë¥¼ ì‚¬ìš©í•˜ì—¬ Keyspaceë¥¼ ìƒì„±í•˜ëŠ” CQL ì˜ˆì‹œì…ë‹ˆë‹¤.
    
    ```sql
    sqlCopy code
    CREATE KEYSPACE IF NOT EXISTS my_keyspace WITH replication = {'class': 'NetworkTopologyStrategy', 'datacenter1': 3} AND durable_writes = true;
    ```
    
    ì´ ëª…ë ¹ì€ **`my_keyspace`**ë¼ëŠ” ì´ë¦„ì˜ Keyspaceë¥¼ ìƒì„±í•˜ê³ , **`datacenter1`**ì—ì„œ ë³µì œ íŒ©í„° 3ì„ ì‚¬ìš©í•˜ë©°, ë‚´êµ¬ì  ì“°ê¸°ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.
    

3) key space ì ‘ì†

```python
USE trend;
```

4) í…Œì´ë¸” ìƒì„±

```sql
CREATE TABLE cardhistory(
	id uuid, userid int, date text, age text, ..., primary key(id));
```

 - PRIMARY KEY ì§€ì • í•„ìˆ˜ 

5) í…Œì´ë¸” ì¡°íšŒ

```sql
SELECT * FROM cardhistory;
```

 ** **where ì˜µì…˜**ì„ ì‚¬ìš©í•˜ë ¤ë©´, ë’¤ì— `allow filtering` ì„ ë¶™ì—¬ì¤˜ì•¼í•œë‹¤.

ì¹´ì‚°ë“œë¼ì—ì„œëŠ” í•„í„°ë§ì„ í•˜ê²Œ ë˜ë©´ ì„±ëŠ¥ì— ì˜í–¥ì´ ê°€ê¸° ë•Œë¬¸ì—, ê·¸ëŸ¼ì—ë„ í•˜ê² ë‹¤ëŠ” ì˜µì…˜ì„ ë¶™ì—¬ì£¼ëŠ” ê²ƒì„.

> **Springê³¼ Cassandra ì—°ê²°**
> 

1) application.ymlì— cassandra ì¶”ê°€

```yaml
spring:
  cassandra:
    contact-points: <ì»¨í…Œì´ë„ˆ ipì£¼ì†Œ>
    keyspace-name: <ìœ„ì—ì„œ ì„¤ì •í•œ keyspace (trend) >
    port: 9042
    local-datacenter: datacenter1
```

 - ìœ„ì— ëª…ì‹œí•œ ì†ì„±ë“¤ì€ ëª¨ë‘ í‘œì‹œë¥¼ í•´ì¤˜ì•¼ Beanì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë¨

 - Spring Boot í•œì •ìœ¼ë¡œ yml íŒŒì¼ ë•ë¶„ì— ë”°ë¡œ CassandraConfig íŒŒì¼ì„ ìƒì„±í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ ì¶”ê°€ ì»¤ìŠ¤í…€ì´ í•„ìš”í•˜ë‹¤ë©´ ìƒì„±í•´ì•¼í•¨(Cassandra Template)

â‡’ **ì¦‰, ymlì— ë‹¤ í‘œì‹œê°€ ì•ˆë˜ì–´ìˆìœ¼ë©´ ConfigíŒŒì¼ì„ ìƒì„±í•´ì„œ ì†ì„±ì„ ì§€ì •í•´ë‹¬ë¼ëŠ” ì˜¤ë¥˜ê°€ ë‚˜ì˜¤ëŠ” ê²ƒ.**

- ğŸ’¡ **Tip: data center í™•ì¸í•˜ëŠ” ë²•**
    
    ```bash
    ./nodetool status 
    ```
    
    ì—¬ê¸°ì„œ data center í™•ì¸ (ë‚œ ì•ˆë³´ì˜€ìŒã…‹)
    
    í˜¹ì€
    
    ```bash
    ./cqlsh <ipì£¼ì†Œ> 9042
    
    > cqlsh : SELECT data_center FROM system.local;
    ```
    
    (ë‹¤ë¥¸ peer nodeì˜ data centerë¥¼ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´, system.local ëŒ€ì‹  system.peers
    

 -

2) Entity

```bash
package com.ssafy.pickachu.domain.statistics.entity;

import com.google.gson.annotations.SerializedName;
import lombok.Data;
import lombok.NoArgsConstructor;
import org.springframework.data.cassandra.core.mapping.PrimaryKey;
import org.springframework.data.cassandra.core.mapping.Table;

import java.util.UUID;

@Data
@NoArgsConstructor
@Table("cardhistory")
public class CardHistoryEntity {

    @PrimaryKey
    private UUID id;
    private int userid;
    private String age;
    private String gender;
    @SerializedName("resUsedDate")
    private String date;
    @SerializedName("resUsedTime")
    private int time;
    @SerializedName("resUsedAmount")
    private int amount;
    @SerializedName("resMemberStoreType")
    private String category;
    private int cardId;
}

```

 - @DataëŠ” lombokì˜ annotationìœ¼ë¡œ GETTER, SETTER, toString, hashCode ë“±ì„ ë§Œë“¤ì–´ì¤Œ

3) Repository

```sql
package com.ssafy.pickachu.domain.statistics.repository;

import com.ssafy.pickachu.domain.statistics.entity.CardHistoryEntity;
import com.ssafy.pickachu.domain.statistics.entity.MyConsumptionEntity;
import org.springframework.data.cassandra.repository.CassandraRepository;
import org.springframework.data.cassandra.repository.Query;
import org.springframework.data.repository.query.Param;
import org.springframework.stereotype.Repository;

import java.util.List;

@Repository
public interface CardHistoryEntityRepository extends CassandraRepository<CardHistoryEntity, Integer> {
    @Query("SELECT * FROM cardhistory WHERE userid = :userid ALLOW FILTERING")
    List<CardHistoryEntity> findMyCardHistoryById(@Param("userid") int userid);
}

```

4) Service

```sql
package com.ssafy.pickachu.domain.statistics.service;

import com.ssafy.pickachu.domain.statistics.response.CardHistoryRes;
import com.ssafy.pickachu.domain.user.entity.User;
import org.springframework.http.ResponseEntity;

public interface CardHistoryService {

    ResponseEntity<CardHistoryRes> saveCardHistoriesByAirflow(String apiKey);

    void saveCardHistories(String payListResult, User user, long id);

}
```

5) SerivceImpl

```sql
package com.ssafy.pickachu.domain.statistics.serviceImpl;

@Slf4j
@Service
@RequiredArgsConstructor
public class CardHistoryServiceImpl implements CardHistoryService {

    private final CardHistoryEntityRepository cardHistoryEntityRepository;

    @Override
    public void saveCardHistories(String payListResult, User user, long cardId) {
        PreparedStatement preparedStatement = cqlSession.prepare(
                "INSERT INTO cardhistory (id, userid, age, amount, cardid, category, date, gender, time) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)"
        );
        BatchStatement batchStatement = BatchStatement.builder(DefaultBatchType.LOGGED).build();

        String userAgeGroup = commonUtil.calculateAge(user.getBirth());

        // ë¬¸ìì—´ ë‚´ìš©ì„ JSONArray ê°ì²´ë¡œ ë³€í™˜
        JSONArray jsonArray = new JSONArray(payListResult);

        // JSONArray ë‚´ìš© ì²˜ë¦¬ ì˜ˆì‹œ
        for (int i = 0; i < jsonArray.length(); i++) {
            JSONObject jsonObject = (JSONObject) jsonArray.get(i);

            CardHistoryEntity history = gson.fromJson(String.valueOf(jsonObject), CardHistoryEntity.class);
            history.setUserid((int) user.getId());
            history.setId(UUID.randomUUID());
            history.setGender(user.getGender());
            history.setAge(userAgeGroup);
            history.setCardId((int) cardId);
            // cardHistoryEntityRepository.save(history);
            // ë°°ì¹˜ ì‘ì—…ì— ì¶”ê°€
            BoundStatement boundStatement = preparedStatement.bind(
                    history.getId(),
                    history.getUserid(),
                    history.getAge(),
                    history.getAmount(),
                    history.getCardId(),
                    history.getCategory(),
                    history.getDate(),
                    history.getGender(),
                    history.getTime()
            );
            batchStatement = batchStatement.add(boundStatement);
        }

        // ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ IO ì¤„ì´ê¸°
        cqlSession.execute(batchStatement);
    }

    @Override
    public ResponseEntity<CardHistoryRes> saveCardHistoriesByAirflow(String apiKey) {

        // API KEY ê²€ì¦
        if(!apiKey.equals(this.apiKey)){
            throw new InvalidApiKeyException("API Keyê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
        }

        // ìœ ì € ì „ì²´ì— ëŒ€í•´ì„œ ë°ì´í„° ìš”ì²­
        List<User> userList = userRepository.findAll();
        CodefToken codefToken = codefRepository.findById(1)
                .orElseGet(() -> {
                    CodefToken token = CodefToken.builder()
                            .id(1)
                            .token(codefApi.GetToken())
                            .updateTime(LocalDateTime.now())
                            .build();
                    return  token;
                });

        // ì–´ì œ í•˜ë£¨ ë‚´ì—­ ë¶ˆëŸ¬ì˜¤ê¸°
        Calendar calendar = Calendar.getInstance();
        SimpleDateFormat dateFormat = new SimpleDateFormat("yyyyMMdd");
        calendar.add(Calendar.DATE, -1);
        String startDay = dateFormat.format(calendar.getTime());
        String endDay = startDay;

        // ìœ ì €ë³„ë¡œ
        for(User user : userList){
            try{
                // ì¹´ë“œë³„ë¡œ
                List<PersonalCards> personalCards = personalCardsRepository.findAllByUserIdAndUseYN(user.getId(), user.getUseYN());
                for(PersonalCards card : personalCards){
                    RegisterCardsReq registerCardsReq = new RegisterCardsReq(
                        card.getCardCompany(), jasyptUtil.decrypt(card.getCardNo()), jasyptUtil.decrypt(card.getCardCompanyId()), jasyptUtil.decrypt(card.getCardCompanyPw())
                    );
                    String payListResult = codefApi.GetUseCardList(registerCardsReq, user, codefToken.getToken(),startDay,endDay);
                    saveCardHistories(payListResult, user, card.getId());
                }
            }catch (IOException e){
                throw new CardInfoIOException("ì¹´ë“œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
            }catch (Exception e){
                e.printStackTrace();
            }

        }

        CardHistoryRes cardHistoryRes = CardHistoryRes.createCardHistoryResponse(
                HttpStatus.OK.value(), "Success", "Success"
        );

        return ResponseEntity.ok(cardHistoryRes);
    }

}

```

### ğŸ’¢ Trouble Shooting

Cassandra, Zeppelinì´ ëª¨ë‘ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì¡ì•„ë¨¹ëŠ”ë°,

í…ŒìŠ¤íŠ¸ë¥¼ ê³„ì† í•˜ë©´ì„œ Cassandraì— IOì‘ì—…ì´ ë¹ˆë²ˆí•´ì ¸ ê²°êµ­ ì„œë²„ê°€ ì£½ê³  ë§ì•˜ë‹¤ â€¦

ì¹´ë“œ í•œ ë²ˆë§Œ ë“±ë¡í•´ë„, ì¹´ë“œ í•˜ë‚˜ ë‹¹ 100ê±´ì˜ ì¹´ë“œ ë‚´ì—­ì´ ìˆë‹¤ë©´ 100ë²ˆì˜ IO ì‘ì—…ì´ ë°œìƒ.

ì‹¬ì§€ì–´ ë„ì»¤ ë³¼ë¥¨ë„ ì‘ì•„ì„œ ë¬¸ì œê°€ í„°ì§„ ê²ƒ ê°™ë‹¤.

ê·¸ë˜ì„œ ì½”ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í–ˆë‹¤.

```java
    private final CardHistoryEntityRepository cardHistoryEntityRepository;

    @Override
    public void saveCardHistories(String payListResult, User user, long cardId) {
        PreparedStatement preparedStatement = cqlSession.prepare(
                "INSERT INTO cardhistory (id, userid, age, amount, cardid, category, date, gender, time) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)"
        );
        BatchStatement batchStatement = BatchStatement.builder(DefaultBatchType.LOGGED).build();

        String userAgeGroup = commonUtil.calculateAge(user.getBirth());

        // ë¬¸ìì—´ ë‚´ìš©ì„ JSONArray ê°ì²´ë¡œ ë³€í™˜
        JSONArray jsonArray = new JSONArray(payListResult);

        // JSONArray ë‚´ìš© ì²˜ë¦¬ ì˜ˆì‹œ
        for (int i = 0; i < jsonArray.length(); i++) {
            JSONObject jsonObject = (JSONObject) jsonArray.get(i);

            CardHistoryEntity history = gson.fromJson(String.valueOf(jsonObject), CardHistoryEntity.class);
            history.setUserid((int) user.getId());
            history.setId(UUID.randomUUID());
            history.setGender(user.getGender());
            history.setAge(userAgeGroup);
            history.setCardId((int) cardId);
            // cardHistoryEntityRepository.save(history);
            // ë°°ì¹˜ ì‘ì—…ì— ì¶”ê°€
            BoundStatement boundStatement = preparedStatement.bind(
                    history.getId(),
                    history.getUserid(),
                    history.getAge(),
                    history.getAmount(),
                    history.getCardId(),
                    history.getCategory(),
                    history.getDate(),
                    history.getGender(),
                    history.getTime()
            );
            batchStatement = batchStatement.add(boundStatement);
        }

        // ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ IO ì¤„ì´ê¸°
        cqlSession.execute(batchStatement);
```

CassandraëŠ” batchì‘ì—…ë„ ì§€ì›í•´ì£¼ê¸° ë•Œë¬¸ì—, ë°°ì¹˜ë¥¼ ì‚¬ìš©í•´ì„œ ì¹´ë“œ í•˜ë‚˜ë‹¹ í•œë²ˆì˜ IO ì‘ì—…ë§Œ ì¼ì–´ë‚˜ë„ë¡ í–ˆë‹¤.

6) Controller

```sql
package com.ssafy.pickachu.domain.statistics.controller;

@RestController
@RequiredArgsConstructor
@CrossOrigin("*")
@RequestMapping("/statistics")
@Tag(name = "Statistics API", description = "ë¹…ë°ì´í„° ë¶„ì‚° ì²˜ë¦¬ í†µê³„ API")
public class StatisticsController {

    private final StatisticsService statisticsService;
    private final CardHistoryService cardHistoryService;

    @Operation(summary = "ê°œì¸ ì†Œë¹„ í†µê³„", description = "ì§€ë‚œë‹¬ ì†Œë¹„ ë‚´ì—­ê³¼ ì—…ì¢… ë¶„ì„, ì¼ìë³„ ì†Œë¹„ ê¸ˆì•¡ í•©ê³„")
    @ApiResponses({
            @ApiResponse(responseCode = "200", description = "(message : \"Success\", code : 200)",
                    content = @Content(schema = @Schema(implementation = MyConsumptionRes.class)))
    })
    @GetMapping("/consumption")
    public ResponseEntity<MyConsumptionRes> getConsumption(@AuthenticationPrincipal PrincipalDetails principalDetails){return statisticsService.getMyConsumption(principalDetails);}

}

```

> **íŒŒì´í”„ë¼ì¸ ìë™í™”ë¥¼ ìœ„í•œ Airflow ì„¤ì¹˜**
> 

[[ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ with Airflow] 4ê°•. ë„ì»¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Airflow ì„¤ì¹˜í•˜ê¸°](https://www.youtube.com/watch?v=_6FaI70td34)

1) docker compose ì„¤ì¹˜

```bash
sudo apt install docker-compose
```

 - ë„ì»¤ëŠ” ì´ë¯¸ ê¹”ë ¤ìˆìœ¼ë¯€ë¡œ ìƒëµí•˜ê³  ë°”ë¡œ ë„ì»¤ ì»´í¬ì¦ˆë¥¼ ì„¤ì¹˜í•œë‹¤.

### **ğŸ’¢** Trouble Shooting

docker pull ì–´ì©Œêµ¬ë¥¼ í• ê¹Œ ì´ê±¸ í• ê¹Œ ê³ ë¯¼í–ˆëŠ”ë°â€¦. ê·¸ëƒ¥ ì‹œí‚¤ëŠ”ëŒ€ë¡œ í•˜ê¸°ë¡œ í–ˆë‹¤.

ê·¼ë° ë„ì»¤ ì»´í¬ì¦ˆë¥¼ ì„¤ì¹˜í•˜ëŠ” ê³¼ì •ì—ì„œ ì¸ì§€.. ì•„ë‹ˆë©´ yaml íŒŒì¼ë”°ë¼ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì—ì„œì¸ì§€ ë­”ì§€ ì›ì¸ì„ ì•„ì§ ì°¾ì§€ëŠ” ëª»í–ˆì§€ë§Œ ë­”ê°€ ì¶©ëŒì´ ìˆì–´ì„œ

ê¸°ì¡´ì— ëŒì•„ê°€ë˜ ë‚˜ì˜ ì†Œì¤‘í•œ ë…¸ë“œë“¤ê³¼ ì¹´ì‚°ë“œë¼ê°€ ëª¨ë‘ êº¼ì¡Œë‹¤â€¦ã… ,ã… 

ë‹¤í–‰íˆ êº¼ì§€ê¸°ë§Œ í•œê±°ë¼ ì„¤ì •í•œ ë‚´ìš©ë“¤ì€ ë‹¤ ê·¸ëŒ€ë¡œì˜€ëŠ”ë°

ssh serviceë„ ë‹¤ì‹œ ì¼œì¤˜ì•¼í–ˆê³ (ë‹¤í–‰íˆ í‚¤ ì§€ë¬¸ ì´ëŸ°ê±°ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©ê°€ëŠ¥ ã…)

ëª¨ë“  daemonì„ ë‹¤ì‹œ ë‹¤ ì‹¤í–‰ì‹œì¼œì¤˜ì•¼í–ˆë‹¤;; ì •ë¦¬í•˜ê¸¸ ì˜í•¨

ì›ì¸ì€ ê³„ì† ì°¾ëŠ” ì¤‘â€¦â€¦

2) airflowë¥¼ ì„¤ì •í•˜ëŠ” docker-compose.yaml íŒŒì¼ ë‹¤ìš´ë°›ê¸°

```bash
curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.5.1/docker-compose.yaml'
```

 - ì°¸ê³ ë¡œ ì €ê±° ìˆ«ì 0ì´ ì•„ë‹Œ ì•ŒíŒŒë²³ Oì„ì— ì£¼ì˜í•˜ì.
(ìˆ«ì 0 í–ˆë‹¤ê°€ ìê¾¸ ë‹¤ìš´ì€ ì•ˆë˜ê³  catì²˜ëŸ¼ ë‚´ìš© ì¶œë ¥ë§Œ ë¨)

3) í•„ìš”í•œ í´ë” ìƒì„±

```bash
mkdir -p ./dags ./logs ./plugins
```

4) env ì„¤ì •(ì•„ë§ˆë„ ì‚¬ìš©ìë¥¼ ì„¤ì •í•˜ëŠ”ë“¯ í•¨)

```bash
 echo -e "AIRFLOW_UID=$(id -u)" > .env
```

 - ì´ê±° í•˜ê³  ë‚˜ë©´ .envíŒŒì¼ì´ ìƒì„±ë˜ê³ , ë‚´ê°€ 1000ë²ˆ ì•„ì´ë””ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— í™•ì¸í•´ë³´ë©´ AIRFLOW_UIDê°€ 1000ì´ë¼ê³  ì§€ì •ë˜ì–´ ìˆì„ ê²ƒì´ë‹¤.

4) airflow-init ì‹¤í–‰

```bash
sudo docker compose up airflow-init
```

> **Airflow ì‹¤í–‰**
> 

1) ë„ì»¤ ì»´í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰

```bash
sudo docker compose up
```

 - í•¨ê»˜ ì„¤ì¹˜ëœ DBë“¤ë„ ê¹”ë ¤ì•¼ ì›¹ì„œë²„ê°€ ê°€ë™ëœë‹¤.

** psë¡œ í™•ì¸

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/339641c4-ee45-47c3-a4ce-941fa69dd23b/Untitled.png)

 - redis, postgl dbë„ ì„¤ì¹˜ë˜ì–´ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆê³ , airflow í¬íŠ¸ëŠ” 8080ì´ë‹¤.

2) ë¸Œë¼ìš°ì €ë¡œ ì ‘ì†

```bash
ë¸Œë¼ìš°ì €ì— <ë‚´ ì™¸ë¶€ ipì£¼ì†Œ>:8080 ìœ¼ë¡œ ì ‘ì†
```

 - ì•„ì´ë””, ë¹„ë²ˆ ëª¨ë‘ airflow (docker-compose.yaml ë³´ë©´ ë‚˜ì™€ìˆìŒ)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/3288f07a-bea6-4386-81ba-2403b020e955/Untitled.png)

3) ê°„ë‹¨í•œ ì†Œê°œ

<ìì£¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë“¤>

- Grid

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/1236cbd8-e342-4a01-80b6-d315fd0191ec/Untitled.png)

ìœ„ì— í† ê¸€ì„ ëˆ„ë¥´ê³  Auto-refreshë„ í•˜ë©´ ë­”ê°€ ëœ¸

- Graph

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/0231a3a3-f870-4d83-9403-4fa127909857/Untitled.png)

taskë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆê³  ìƒíƒœë„ í™•ì¸ ê°€ëŠ¥

- Code

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/1e797c7c-4a13-48d9-9312-4af5a8b6963c/Untitled.png)

UIìƒì—ì„œ ì½”ë“œë„ ì‘ì„±í•  ìˆ˜ ìˆë‹¤.

4) DAG íŒŒì¼ ì‘ì„±

- **Airflow ê°„ë‹¨í•œ ê°œë…**
    
    [Airflow DAG ìƒì„±(Bash Operator)]
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/558f9287-9ef8-478e-8914-919afbb012f7/Untitled.png)
    
    - ì˜¤í¼ë ˆì´í„°
        
        : íŠ¹ì • í–‰ìœ„ë¥¼ í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ëª¨ì•„ ë†“ì€ í´ë˜ìŠ¤, ì„¤ê³„ë„
        
    - Task
        
        : ì˜¤í¼ë ˆì´í„°ì—ì„œ ê°ì²´í™”(ì¸ìŠ¤í„´ìŠ¤í™”)ë˜ì–´ DAGì—ì„œ ì‹¤í–‰ê°€ëŠ¥í•œ ì˜¤ë¸Œì íŠ¸
        
    - Bash Operator
        
        : ì‰˜ ìŠ¤í¬ë¦½íŠ¸ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ëŠ” ì˜¤í¼ë ˆì´í„°
        
    
    [Taskì˜ ìˆ˜í–‰ ì£¼ì²´]
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/f8449257-e309-4225-959e-1a13343dba68/Untitled.png)
    
    - ìŠ¤ì¼€ì¤„ëŸ¬
        
        : DAG Parsing í›„ DB ì •ë³´ ì €ì¥
        
        : DAG ì‹œì‘ ì‹œê°„ ê²°ì •
        
    - ì›Œì»¤
        
        : ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
        
    
    (ì‹œì‘ ì§€ì‹œí•  ë•Œ íë¥¼ ì‚¬ìš©)
    

- **example bash operatorì˜ˆì‹œ**

```python
from __future__ import annotations
import datetime
import pendulum # datetimeì„ ì¢€ ë” ì‚¬ìš©í•˜ê¸° ì‰½ê²Œí•¨

from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator

def load_data_to_cassandra_by_api():
    api_url = 'http://j10d110.p.ssafy.io/api/load-data'
    response = requests.get(api_url)

    #ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if response.status_code == 200:
        print("Data successfully loaded to Cassandra.")
    else:
        raise Exception("Failed to load data to Cassandra.")

zeppelin_notebook_run_command_list = [
"""
curl -X POST http://j10d110a.p.ssafy.io:18888/#/notebook/2JSXPJ6AT
""",
"""
curl -X POST http://j10d110a.p.ssafy.io:18888/#/notebook/2JSACMPQ9
"""
]

with DAG(
        # dagì˜ ì´ë¦„(íŒŒì¼ ì´ë¦„ê³¼ëŠ” ë³„ê°œì„, but ì¼ì¹˜ì‹œí‚¤ëŠ” ê²ƒì´ ì¢‹ìŒ)
        dag_id="dags_d110",
        # cron schedule. ì–¸ì œ ì‹¤í–‰ë ì§€ ì§€ì •. "ë¶„ ì‹œ ì¼ ì›” ìš”ì¼"
        schedule_interval="0 16 * * *",
        # dagì´ ì–¸ì œë¶€í„° ëŒê±´ì§€, catchup : start dateì™€ í˜„ì¬ ì‹œê°„ ì‚¬ì´ì˜ ëˆ„ë½ëœ ë¶€ë¶„ì„ ëª¨ë‘ ëŒë¦´ ê²ƒì¸ì§€ ë§ ê²ƒì¸ì§€(trueë©´ ëŒë¦¼. ë‹¨, ì°¨ë¡€ì°¨ë¡€ ë„ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í•œêº¼ë²ˆì— ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨)
        start_date=pendulum.datetime(2024, 3, 29, tz="Asia/Seoul"),
        catchup=False,
        # timeout ê°’ ì„¤ì •. ì—†ì–´ë„ ëœë‹¤.
        # dagrun_timeout=datetime.timedelta(minutes=60),
        # ë¸Œë¼ìš°ì €ì—ì„œ dag ì´ë¦„ ë°‘ì— ë³´ì´ëŠ” íƒœê·¸ ì„¤ì •. íƒœê·¸ ë³„ë¡œ ëª¨ì•„ì„œ ë³´ê¸°ê°€ ê°€ëŠ¥(ë”°ë¼ì„œ Optional)
        tags=["spring api", "zeppelin notebook"],
        # ì•„ë˜ì— ì •ì˜í•  Taskë“¤ì— ê³µí†µìœ¼ë¡œ ì •ì˜í•  íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤ë©´ ì§€ì •
        # params={"example_key": "example_value"},
) as dag:
    # [ë°ì´í„° ì ì¬]
    insert_codef_data_to_cassandra_by_spring_api = PythonOperator( # taskì˜ ì´ë¦„ì„. Operatorë¡œ ë§Œë“¤ì–´ì§€ëŠ” task ê°ì²´ì˜ ì´ë¦„
        task_id="insert_codef_data_to_cassandra_by_spring_api", # ë¸Œë¼ìš°ì €ì—ì„œ ë´¤ì„ ë•Œ graphì—ì„œ ë‚˜ì˜¤ëŠ” task ì´ë¦„. ë§ˆì°¬ê°€ì§€ë¡œ ê°ì²´ ì´ë¦„ê³¼ ë³„ê°œì§€ë§Œ ì¼ì¹˜í•˜ë„ë¡
        python_callable=load_data_to_cassandra_by_api,
    )
    # [ë°ì´í„° ë¶„ì„]
    for i in range(2):
        task = BashOperator(
            task_id="zeppelin_task_" + str(i),
            bash_command=zeppelin_notebook_run_command_list[i],
        )
        insert_codef_data_to_cassandra_by_spring_api >> task

```

 - >> : insert_codef_data_to_cassandra_by_spring_apiê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰ë˜ë©´ taskê°€ ìˆ˜í–‰ë˜ë„ë¡ ì˜ì¡´ì„±ì„ ì„¤ì •í•¨. ê·¸ë¦¬ê³  ì € insertëŠ” í•œë²ˆë§Œ ìˆ˜í–‰ëœë‹¤.

5) docker-compose.yamlì— volumesë¶€ë¶„ì„ ìˆ˜ì •(ì„ íƒ)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/9eb5318d-fb4e-4cd4-ab31-d8a51ba80e99/a20d2889-6a68-4e6e-9858-cb77d631554b/Untitled.png)

 - `${AIRFLOW_PROJ_DIR:-.}`  : AIRFLOW_PROJ_DIRì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ . ì„ ì¶œë ¥í•œë‹¤.

 - ì¦‰, : ê¸°ì¤€ ì• ë¬¸ì¥ì€ ./dags ì¸ ê²ƒì„.

 - : ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì™¼ìª½ì€ ubuntu(ec2)ì˜ ë³¼ë¥¨, ì˜¤ë¥¸ìª½ì€ ì»¨í…Œì´ë„ˆì˜ ë³¼ë¥¨

 - ë§Œì•½ dags íŒŒì¼ì„ airflowë¼ëŠ” í´ë” ì•„ë˜ì— dags í´ë”ì— ì €ì¥í•´ë†¨ë‹¤ë©´, (ê·¸ë¦¬ê³  ì•ìœ¼ë¡œ ê³„ì† ê±°ê¸°ì„œ íŒŒì¼ì„ ë§Œë“¤ê±°ë¼ë©´, /dags ë¶€ë¶„ì„ /airflow/dagsë¡œ ìˆ˜ì •í•˜ë©´ ëœë‹¤.)

<<ìˆ˜ì •>>

ì´ìœ  : jwtí† í°ì„ ìš°íšŒ í•˜ê±°ë‚˜, í•œë²ˆ ë°›ê±°ë‚˜ í•´ì•¼ ë˜ëŠ”ë° ì¼ë‹¨ ìš°íšŒ í•˜ê³  ë‚˜ë¦„ì˜ ë³´ì•ˆ ì •ì±…ì„ ì¶”ê°€

```python
from __future__ import annotations
import datetime
import pendulum # datetimeì„ ì¢€ ë” ì‚¬ìš©í•˜ê¸° ì‰½ê²Œí•¨
import os
import requests

from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator

def load_data_to_cassandra_by_api():
    api_url = 'http://j10d110.p.ssafy.io:8080/api/statistics/airflow'
    api_key = os.getenv('AIRFLOW_API_KEY', 'default_value')
    headers = {
        "AIRFLOW-API-KEY":api_key,
    }
    response = requests.get(api_url, headers=headers)

    #ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if response.status_code == 200:
        print("Data successfully loaded to Cassandra.")
    else:
        raise Exception(f"{response.status_code}: Failed to load data to Cassandra.")

zeppelin_notebook_run_command_list = [
"""
curl -X POST http://j10d110a.p.ssafy.io:18888/#/notebook/2JSXPJ6AT
""",
"""
curl -X POST http://j10d110a.p.ssafy.io:18888/#/notebook/2JSACMPQ9
"""
]

with DAG(
        # dagì˜ ì´ë¦„(íŒŒì¼ ì´ë¦„ê³¼ëŠ” ë³„ê°œì„, but ì¼ì¹˜ì‹œí‚¤ëŠ” ê²ƒì´ ì¢‹ìŒ)
        dag_id="dags_d110",
        # cron schedule. ì–¸ì œ ì‹¤í–‰ë ì§€ ì§€ì •. "ë¶„ ì‹œ ì¼ ì›” ìš”ì¼"
        schedule_interval="0 7 * * *",
        # dagì´ ì–¸ì œë¶€í„° ëŒê±´ì§€, catchup : start dateì™€ í˜„ì¬ ì‹œê°„ ì‚¬ì´ì˜ ëˆ„ë½ëœ ë¶€ë¶„ì„ ëª¨ë‘ ëŒë¦´ ê²ƒì¸ì§€ ë§ ê²ƒì¸ì§€(trueë©´ ëŒë¦¼. ë‹¨, ì°¨ë¡€ì°¨ë¡€ ë„ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í•œêº¼ë²ˆì— ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨)
        start_date=pendulum.datetime(2024, 3, 29, tz="Asia/Seoul"),
        catchup=False,
        # timeout ê°’ ì„¤ì •. ì—†ì–´ë„ ëœë‹¤.
        # dagrun_timeout=datetime.timedelta(minutes=60),
        # ë¸Œë¼ìš°ì €ì—ì„œ dag ì´ë¦„ ë°‘ì— ë³´ì´ëŠ” íƒœê·¸ ì„¤ì •. íƒœê·¸ ë³„ë¡œ ëª¨ì•„ì„œ ë³´ê¸°ê°€ ê°€ëŠ¥(ë”°ë¼ì„œ Optional)
        tags=["spring api", "zeppelin notebook"],
        # ì•„ë˜ì— ì •ì˜í•  Taskë“¤ì— ê³µí†µìœ¼ë¡œ ì •ì˜í•  íŒŒë¼ë¯¸í„°ê°€ ìˆë‹¤ë©´ ì§€ì •
        # params={"example_key": "example_value"},
) as dag:
    # [ë°ì´í„° ì ì¬]
    insert_codef_data_to_cassandra_by_spring_api = PythonOperator( # taskì˜ ì´ë¦„ì„. Operatorë¡œ ë§Œë“¤ì–´ì§€ëŠ” task ê°ì²´ì˜ ì´ë¦„
        task_id="insert_codef_data_to_cassandra_by_spring_api", # ë¸Œë¼ìš°ì €ì—ì„œ ë´¤ì„ ë•Œ graphì—ì„œ ë‚˜ì˜¤ëŠ” task ì´ë¦„. ë§ˆì°¬ê°€ì§€ë¡œ ê°ì²´ ì´ë¦„ê³¼ ë³„ê°œì§€ë§Œ ì¼ì¹˜í•˜ë„ë¡
        python_callable=load_data_to_cassandra_by_api,
    )
    # [ë°ì´í„° ë¶„ì„]
    for i in range(2):
        task = BashOperator(
            task_id="zeppelin_task_" + str(i),
            bash_command=zeppelin_notebook_run_command_list[i],
        )
        insert_codef_data_to_cassandra_by_spring_api >> task

```

> **ì´í›„ ì‘ì—…í•  ë‚´ìš©**
> 

1) ë§¤ë‹¬ ì›” ì†Œë¹„ ë°ì´í„° ì ì¬ í•˜ê¸°

Zeppelinì—ì„œ Cassandra ë°ì´í„°ì…‹ì„ hdfsë¡œ ì˜®ê¸°ëŠ” ì‘ì—… ìˆ˜í–‰í•˜ê¸° â†’ ë§¤ë‹¬ 1ì¼ Airflow ì‹¤í–‰ë˜ë„ë¡ í•˜ê¸°

```python
# Cassandraì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
df = spark.read \
    .format("org.apache.spark.sql.cassandra") \
    .options(table="TABLE_NAME", keyspace="KEYSPACE_NAME") \
    .load()

# ì»¬ëŸ¼ ì¡°ì • ... (user id ê°™ì€ ë¶€ë¶„ì€ ì œê±°)

# hdfsì— ì“°ê¸°
df.write.format("parquet").save("hdfs:///path/to/hdfs/directory")

# ì´í›„ì— í˜„ì¬ hdfsì—ì„œ ë¶ˆëŸ¬ì˜¤ëŠ” ë°ì´í„° ì‘ì—… ë˜‘ê°™ì´ ìˆ˜í–‰í•˜ê¸°...
# ì›”ê°„, ì—°ê°„ë„ ì „ì²´ ë¶„ì„ì„ ëŒë ¤ë´ë„ ì¢‹ì„ë“¯
```

2) ë³´ì•ˆì„ ìœ„í•´ hadoopì— kerberos ì ìš©í•˜ê¸°

